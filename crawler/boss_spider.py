from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import urllib.parse
import time
from .browser_manager import BrowserManager


class BossSpider:
    def __init__(self):
        self.browser = BrowserManager()
        self.base_url = "https://www.zhipin.com"
        
    def start(self):
        """å¯åŠ¨çˆ¬è™«"""
        if not self.browser.setup_browser():
            return False
        return True
    
    def login_with_manual_help(self):
        """æ‰‹åŠ¨ç™»å½•è¾…åŠ©"""
        print("=== æ‰‹åŠ¨ç™»å½•æµç¨‹ ===")
        print("1. æ­£åœ¨æ‰“å¼€Bossç›´è˜ç™»å½•é¡µé¢...")
        
        # è®¿é—®é¦–é¡µ
        self.browser.driver.get(f"{self.base_url}/shenzhen/")
        self.browser.random_delay(2, 4)
        
        # å°è¯•åŠ è½½å·²ä¿å­˜çš„cookies
        if self.browser.load_cookies():
            self.browser.driver.refresh()
            self.browser.random_delay(3, 5)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
            if self.check_login_status():
                print("âœ… ä½¿ç”¨ä¿å­˜çš„cookiesç™»å½•æˆåŠŸ!")
                return True
            else:
                print("âš ï¸ ä¿å­˜çš„cookieså·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
        
        print("2. è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®Œæˆç™»å½•ï¼ˆå»ºè®®ä½¿ç”¨æ‰«ç ç™»å½•ï¼‰")
        print("3. ç™»å½•å®Œæˆåï¼ŒæŒ‰å›è½¦é”®ç»§ç»­...")
        input()
        
        # éªŒè¯ç™»å½•çŠ¶æ€
        if self.check_login_status():
            print("âœ… ç™»å½•æˆåŠŸ!")
            self.browser.save_cookies()
            return True
        else:
            print("âŒ ç™»å½•éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç™»å½•çŠ¶æ€")
            return False
    
    def check_login_status(self):
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        try:
            # æŸ¥æ‰¾ç™»å½•åçš„ç”¨æˆ·ç›¸å…³å…ƒç´ 
            # Bossç›´è˜ç™»å½•åé€šå¸¸ä¼šæœ‰ç”¨æˆ·å¤´åƒæˆ–è€…ç”¨æˆ·åæ˜¾ç¤º
            user_elements = [
                "//img[contains(@class, 'avatar')]",
                "//span[contains(@class, 'name')]",
                "//div[contains(@class, 'user')]"
            ]
            
            for xpath in user_elements:
                try:
                    element = self.browser.driver.find_element(By.XPATH, xpath)
                    if element.is_displayed():
                        return True
                except NoSuchElementException:
                    continue
            
            # å¦‚æœæ‰¾ä¸åˆ°ç”¨æˆ·å…ƒç´ ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•æŒ‰é’®
            login_buttons = [
                "//a[contains(text(), 'ç™»å½•')]",
                "//button[contains(text(), 'ç™»å½•')]"
            ]
            
            for xpath in login_buttons:
                try:
                    element = self.browser.driver.find_element(By.XPATH, xpath)
                    if element.is_displayed():
                        return False  # æœ‰ç™»å½•æŒ‰é’®è¯´æ˜æœªç™»å½•
                except NoSuchElementException:
                    continue
                    
            return True  # æ—¢æ²¡æœ‰ç”¨æˆ·å…ƒç´ ä¹Ÿæ²¡æœ‰ç™»å½•æŒ‰é’®ï¼Œå‡è®¾å·²ç™»å½•
            
        except Exception as e:
            print(f"æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False
    
    def search_jobs(self, keyword, city_code="101280600", max_jobs=20, fetch_details=False):
        """æœç´¢å²—ä½"""
        print(f"ğŸ” å¼€å§‹æœç´¢å²—ä½: {keyword}")
        
        # æ„é€ æœç´¢URL
        encoded_keyword = urllib.parse.quote(keyword)
        search_url = f"{self.base_url}/web/geek/jobs?query={encoded_keyword}&city={city_code}"
        
        print(f"è®¿é—®æœç´¢é¡µé¢: {search_url}")
        self.browser.driver.get(search_url)
        self.browser.random_delay(3, 5)
        
        # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
        self.browser.simulate_human_behavior()
        
        jobs = []
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            print("ç­‰å¾…å²—ä½åˆ—è¡¨åŠ è½½...")
            self.browser.random_delay(5, 8)  # å¢åŠ ç­‰å¾…æ—¶é—´
            
            # æ»šåŠ¨åŠ è½½æ›´å¤šå²—ä½
            print("æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå²—ä½...")
            for i in range(3):  # æ»šåŠ¨3æ¬¡
                self.browser.driver.execute_script("window.scrollBy(0, 1000);")
                self.browser.random_delay(2, 3)
                print(f"ç¬¬{i+1}æ¬¡æ»šåŠ¨å®Œæˆ")
            
            # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
            self.browser.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            self.browser.random_delay(3, 5)
            
            # å°è¯•å¤šç§å¯èƒ½çš„å²—ä½åˆ—è¡¨é€‰æ‹©å™¨
            possible_selectors = [
                ".job-list-box",
                ".job-card-wrapper", 
                ".job-list",
                ".search-job-result",
                "[ka='search-job-result']",
                ".job-primary"
            ]
            
            job_elements = []
            for selector in possible_selectors:
                try:
                    elements = self.browser.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                        job_elements = elements
                        break
                except:
                    continue
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡XPathæŸ¥æ‰¾
            if not job_elements:
                xpath_selectors = [
                    "//li[contains(@class, 'job')]",
                    "//div[contains(@class, 'job')]",
                    "//a[contains(@href, '/job_detail/')]"
                ]
                
                for xpath in xpath_selectors:
                    try:
                        elements = self.browser.driver.find_elements(By.XPATH, xpath)
                        if elements:
                            print(f"âœ… ä½¿ç”¨XPath '{xpath}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                            job_elements = elements
                            break
                    except:
                        continue
            
            print(f"æ‰¾åˆ° {len(job_elements)} ä¸ªå²—ä½")
            
            for i, job_element in enumerate(job_elements[:max_jobs]):
                try:
                    job_info = self.extract_job_info(job_element)
                    if job_info:
                        # å¦‚æœéœ€è¦è·å–è¯¦æƒ…ï¼Œå¹¶ä¸”æœ‰URL
                        if fetch_details and job_info.get('url'):
                            print(f"ğŸ” è·å–ç¬¬{i+1}ä¸ªå²—ä½çš„è¯¦ç»†ä¿¡æ¯...")
                            job_details = self.get_job_detail(job_info['url'])
                            # å°†è¯¦ç»†ä¿¡æ¯åˆå¹¶åˆ°åŸºæœ¬ä¿¡æ¯ä¸­
                            job_info.update(job_details)
                            # è·å–è¯¦æƒ…åéœ€è¦æ›´é•¿çš„å»¶è¿Ÿ
                            self.browser.random_delay(2, 4)
                        
                        jobs.append(job_info)
                        print(f"âœ… ç¬¬{i+1}ä¸ªå²—ä½: {job_info['title']} - {job_info['company']}")
                    
                    # éšæœºå»¶è¿Ÿ
                    self.browser.random_delay(0.5, 1.5)
                    
                except Exception as e:
                    print(f"âŒ æå–ç¬¬{i+1}ä¸ªå²—ä½ä¿¡æ¯å¤±è´¥: {e}")
                    continue
        
        except TimeoutException:
            print("âŒ é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå¯èƒ½éœ€è¦éªŒè¯ç™»å½•çŠ¶æ€æˆ–ç½‘ç«™ç»“æ„å·²å˜åŒ–")
        except Exception as e:
            print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        
        print(f"ğŸ¯ æˆåŠŸè·å– {len(jobs)} ä¸ªå²—ä½ä¿¡æ¯")
        return jobs
    
    def extract_job_info(self, job_element):
        """æå–å²—ä½ä¿¡æ¯"""
        try:
            job_info = {}
            
            # å²—ä½æ ‡é¢˜ - å°è¯•å¤šç§é€‰æ‹©å™¨
            title_selectors = [
                ".job-title a", ".job-name a", "a[ka='search-job-title']", 
                ".job-name", ".title", "h3 a", ".job-title"
            ]
            title_element = None
            for selector in title_selectors:
                try:
                    title_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    if title_element.text.strip():
                        break
                except:
                    continue
            
            if title_element:
                job_info['title'] = title_element.text.strip()
                job_info['url'] = title_element.get_attribute('href') or ""
            else:
                job_info['title'] = "æ ‡é¢˜è·å–å¤±è´¥"
                job_info['url'] = ""
            
            # å…¬å¸åç§° - å°è¯•å¤šç§é€‰æ‹©å™¨
            company_selectors = [
                ".company-name a", ".company-name", ".company a", 
                "[ka='search-job-company']", ".company-text", 
                ".company-info a", ".info-company", ".job-company a",
                "a[href*='/company/']", ".name", ".text"
            ]
            company_element = None
            for selector in company_selectors:
                try:
                    company_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    if company_element.text.strip():
                        print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ°å…¬å¸: {company_element.text.strip()}")
                        break
                except:
                    continue
            
            # å¦‚æœCSSé€‰æ‹©å™¨éƒ½å¤±è´¥ï¼Œå°è¯•XPath
            if not company_element:
                xpath_selectors = [
                    ".//a[contains(@href, '/company/')]",
                    ".//div[contains(@class, 'company')]//a",
                    ".//span[contains(@class, 'name')]"
                ]
                for xpath in xpath_selectors:
                    try:
                        company_element = job_element.find_element(By.XPATH, xpath)
                        if company_element.text.strip():
                            print(f"âœ… ä½¿ç”¨XPath '{xpath}' æ‰¾åˆ°å…¬å¸: {company_element.text.strip()}")
                            break
                    except:
                        continue
            
            if not company_element:
                # è°ƒè¯•: è¾“å‡ºå…ƒç´ çš„HTMLå†…å®¹
                print(f"âš ï¸ å…¬å¸ä¿¡æ¯è·å–å¤±è´¥ï¼Œå…ƒç´ å†…å®¹: {job_element.get_attribute('innerHTML')[:200]}...")
            
            job_info['company'] = company_element.text.strip() if company_element else "å…¬å¸ä¿¡æ¯è·å–å¤±è´¥"
            
            # è–ªèµ„ - å°è¯•å¤šç§é€‰æ‹©å™¨
            salary_selectors = [
                ".salary", ".red", ".job-limit .red", "[ka='search-job-salary']",
                ".job-salary", ".pay", ".price", ".money", 
                "span[class*='salary']", "span[class*='pay']", "em"
            ]
            salary_element = None
            for selector in salary_selectors:
                try:
                    salary_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    if salary_element.text.strip() and any(char in salary_element.text for char in ['K', 'k', 'ä¸‡', 'åƒ', 'å…ƒ', 'Â¥', '$']):
                        print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ°è–ªèµ„: {salary_element.text.strip()}")
                        break
                except:
                    continue
            
            # å¦‚æœCSSé€‰æ‹©å™¨å¤±è´¥ï¼Œå°è¯•XPath
            if not salary_element:
                xpath_selectors = [
                    ".//span[contains(text(), 'K') or contains(text(), 'k') or contains(text(), 'ä¸‡')]",
                    ".//em[contains(text(), 'K') or contains(text(), 'k') or contains(text(), 'ä¸‡')]",
                    ".//*[contains(@class, 'red')]"
                ]
                for xpath in xpath_selectors:
                    try:
                        salary_element = job_element.find_element(By.XPATH, xpath)
                        if salary_element.text.strip() and any(char in salary_element.text for char in ['K', 'k', 'ä¸‡', 'åƒ', 'å…ƒ', 'Â¥', '$']):
                            print(f"âœ… ä½¿ç”¨XPath '{xpath}' æ‰¾åˆ°è–ªèµ„: {salary_element.text.strip()}")
                            break
                    except:
                        continue
            
            if not salary_element:
                # è°ƒè¯•: è¾“å‡ºå…ƒç´ å†…å®¹å¯»æ‰¾è–ªèµ„
                element_text = job_element.text
                print(f"âš ï¸ è–ªèµ„è·å–å¤±è´¥ï¼Œå…ƒç´ æ–‡æœ¬ç‰‡æ®µ: {element_text[:100]}...")
            
            job_info['salary'] = salary_element.text.strip() if salary_element else "è–ªèµ„ä¿¡æ¯è·å–å¤±è´¥"
            
            # å²—ä½æ ‡ç­¾/è¦æ±‚
            tag_selectors = [
                ".tag-list .tag", ".job-tags .tag", ".info-desc span", ".job-limit span"
            ]
            job_info['tags'] = []
            for selector in tag_selectors:
                try:
                    tags_elements = job_element.find_elements(By.CSS_SELECTOR, selector)
                    if tags_elements:
                        job_info['tags'] = [tag.text.strip() for tag in tags_elements if tag.text.strip()]
                        break
                except:
                    continue
            
            # å…¬å¸ä¿¡æ¯
            company_info_selectors = [
                ".company-tag-list", ".company-info", ".company-text"
            ]
            job_info['company_info'] = ""
            for selector in company_info_selectors:
                try:
                    company_info_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    if company_info_element.text.strip():
                        job_info['company_info'] = company_info_element.text.strip()
                        break
                except:
                    continue
            
            # å¦‚æœè·å–åˆ°äº†åŸºæœ¬ä¿¡æ¯ï¼Œè®¤ä¸ºæå–æˆåŠŸ
            if job_info['title'] != "æ ‡é¢˜è·å–å¤±è´¥":
                return job_info
            else:
                print(f"âš ï¸ å²—ä½ä¿¡æ¯æå–ä¸å®Œæ•´: {job_info}")
                return job_info  # å³ä½¿ä¸å®Œæ•´ä¹Ÿè¿”å›ï¼Œè®©AIå»åˆ¤æ–­
                
        except Exception as e:
            print(f"æå–å²—ä½ä¿¡æ¯å¤±è´¥: {e}")
            # è¿”å›åŸºç¡€ä¿¡æ¯ï¼Œè‡³å°‘èƒ½çœ‹åˆ°å…ƒç´ å†…å®¹
            try:
                return {
                    'title': job_element.text[:50] + "..." if len(job_element.text) > 50 else job_element.text,
                    'company': "ä¿¡æ¯æå–å¤±è´¥",
                    'salary': "æœªçŸ¥",
                    'tags': [],
                    'company_info': "",
                    'url': ""
                }
            except:
                return None
    
    def get_job_detail(self, job_url):
        """è·å–å²—ä½è¯¦æƒ… - å¢å¼ºç‰ˆæœ¬"""
        try:
            print(f"ğŸ“„ è·å–å²—ä½è¯¦æƒ…: {job_url}")
            self.browser.driver.get(job_url)
            self.browser.random_delay(3, 5)
            
            job_detail = {
                'url': job_url,
                'job_description': '',
                'job_requirements': '',
                'company_details': '',
                'benefits': '',
                'department': '',
                'work_location': '',
                'experience_required': '',
                'education_required': ''
            }
            
            # 1. è·å–èŒä½æè¿° - å¤šç§é€‰æ‹©å™¨
            description_selectors = [
                ".job-sec-text",
                ".job-detail-text", 
                ".job-detail-section .text",
                ".job-desc .detail-content",
                ".job-content .text",
                "[data-ka='job-detail-desc']"
            ]
            
            for selector in description_selectors:
                try:
                    desc_element = self.browser.driver.find_element(By.CSS_SELECTOR, selector)
                    if desc_element.text.strip():
                        job_detail['job_description'] = desc_element.text.strip()
                        print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' è·å–åˆ°èŒä½æè¿°")
                        break
                except:
                    continue
            
            # 2. è·å–å²—ä½è¦æ±‚ - é€šå¸¸åœ¨æè¿°çš„ç‰¹å®šéƒ¨åˆ†
            requirements_keywords = ["ä»»èŒè¦æ±‚", "å²—ä½è¦æ±‚", "èŒä½è¦æ±‚", "è¦æ±‚", "Requirement"]
            description_text = job_detail['job_description']
            
            for keyword in requirements_keywords:
                if keyword in description_text:
                    # æå–å…³é”®è¯åçš„å†…å®¹ä½œä¸ºè¦æ±‚
                    idx = description_text.find(keyword)
                    if idx != -1:
                        # è·å–å…³é”®è¯åçš„å†…å®¹ï¼Œé™åˆ¶é•¿åº¦
                        requirements_part = description_text[idx:idx+500]
                        job_detail['job_requirements'] = requirements_part
                        break
            
            # 3. è·å–å…¬å¸è¯¦ç»†ä¿¡æ¯
            company_selectors = [
                ".company-info .intro",
                ".company-detail .text", 
                ".company-content",
                ".company-desc",
                "[data-ka='company-intro']"
            ]
            
            for selector in company_selectors:
                try:
                    company_element = self.browser.driver.find_element(By.CSS_SELECTOR, selector)
                    if company_element.text.strip():
                        job_detail['company_details'] = company_element.text.strip()
                        print(f"âœ… è·å–åˆ°å…¬å¸è¯¦æƒ…")
                        break
                except:
                    continue
            
            # 4. è·å–ç¦åˆ©å¾…é‡ä¿¡æ¯
            benefits_selectors = [
                ".job-tags .tag",
                ".welfare-list .welfare-item",
                ".benefits .benefit-item",
                ".job-benefit .item"
            ]
            
            benefits_list = []
            for selector in benefits_selectors:
                try:
                    benefit_elements = self.browser.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in benefit_elements:
                        benefit_text = element.text.strip()
                        if benefit_text and len(benefit_text) > 1:
                            benefits_list.append(benefit_text)
                    if benefits_list:
                        job_detail['benefits'] = ', '.join(benefits_list)
                        print(f"âœ… è·å–åˆ°ç¦åˆ©ä¿¡æ¯: {len(benefits_list)}é¡¹")
                        break
                except:
                    continue
            
            # 5. è·å–å…¶ä»–è¯¦ç»†ä¿¡æ¯
            try:
                # å·¥ä½œåœ°ç‚¹
                location_selectors = [".location-detail", ".work-addr", ".job-location"]
                for selector in location_selectors:
                    try:
                        location_element = self.browser.driver.find_element(By.CSS_SELECTOR, selector)
                        if location_element.text.strip():
                            job_detail['work_location'] = location_element.text.strip()
                            break
                    except:
                        continue
                
                # ç»éªŒè¦æ±‚
                exp_selectors = [".job-primary .red:contains('ç»éªŒ')", ".experience-require"]
                for selector in exp_selectors:
                    try:
                        exp_element = self.browser.driver.find_element(By.CSS_SELECTOR, selector)
                        if exp_element.text.strip():
                            job_detail['experience_required'] = exp_element.text.strip()
                            break
                    except:
                        continue
                        
            except Exception as e:
                print(f"âš ï¸ è·å–é¢å¤–ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            
            # è¾“å‡ºè·å–æƒ…å†µç»Ÿè®¡
            filled_fields = sum(1 for v in job_detail.values() if v)
            print(f"ğŸ“Š è¯¦æƒ…è·å–å®Œæˆ: {filled_fields}/{len(job_detail)} ä¸ªå­—æ®µæœ‰å†…å®¹")
            
            return job_detail
            
        except Exception as e:
            print(f"âŒ è·å–å²—ä½è¯¦æƒ…å¤±è´¥: {e}")
            return {
                'url': job_url,
                'job_description': '',
                'job_requirements': '',
                'company_details': '',
                'benefits': '',
                'department': '',
                'work_location': '',
                'experience_required': '',
                'education_required': ''
            }
    
    def close(self):
        """å…³é—­çˆ¬è™«"""
        self.browser.close()