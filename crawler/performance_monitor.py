#!/usr/bin/env python3
"""
æ€§èƒ½ç›‘æ§å™¨
æä¾›å®æ—¶æ€§èƒ½åˆ†æã€ç“¶é¢ˆæ£€æµ‹å’Œä¼˜åŒ–å»ºè®®
"""

import logging
import time
import asyncio

# å¯é€‰ä¾èµ–
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("psutilæœªå®‰è£…ï¼Œéƒ¨åˆ†æ€§èƒ½ç›‘æ§åŠŸèƒ½å°†è¢«ç¦ç”¨")
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from collections import deque, defaultdict
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: float
    metric_name: str
    value: float
    unit: str
    category: str = "general"
    details: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.details is None:
            self.details = {}


@dataclass
class SystemSnapshot:
    """ç³»ç»Ÿå¿«ç…§"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    disk_io_read_mb: float
    disk_io_write_mb: float
    network_sent_mb: float
    network_recv_mb: float
    active_threads: int
    open_files: int


@dataclass 
class CrawlerPerformance:
    """çˆ¬è™«æ€§èƒ½æ•°æ®"""
    task_id: str
    keyword: str
    city: str
    start_time: float
    end_time: float
    total_jobs: int
    success_rate: float
    avg_page_load_time: float
    avg_extraction_time: float
    cache_hit_rate: float
    retry_count: int
    error_types: Dict[str, int]
    bottlenecks: List[str]


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, history_size: int = 1000):
        self.history_size = history_size
        self.metrics_history: deque = deque(maxlen=history_size)
        self.system_snapshots: deque = deque(maxlen=100)
        self.crawler_performances: deque = deque(maxlen=200)
        
        # å®æ—¶ç»Ÿè®¡
        self.current_metrics: Dict[str, PerformanceMetric] = {}
        self.alert_thresholds = {
            'cpu_percent': 80.0,
            'memory_percent': 85.0,
            'page_load_time': 15.0,
            'extraction_time': 30.0,
            'error_rate': 0.3,
            'cache_miss_rate': 0.7
        }
        
        # æ€§èƒ½åˆ†æå™¨
        self.bottleneck_detector = BottleneckDetector()
        self.trend_analyzer = TrendAnalyzer()
        
        # ç›‘æ§çŠ¶æ€
        self.is_monitoring = False
        self.monitor_task: Optional[asyncio.Task] = None
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total_monitored_tasks': 0,
            'avg_task_duration': 0.0,
            'peak_cpu_usage': 0.0,
            'peak_memory_usage': 0.0,
            'total_alerts': 0,
            'performance_score': 100.0
        }
    
    async def start_monitoring(self, interval: float = 5.0):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        if self.is_monitoring:
            return
        
        self.is_monitoring = True
        self.monitor_task = asyncio.create_task(self._monitor_loop(interval))
        logger.info(f"ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ (é—´éš”: {interval}s)")
    
    async def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        if not self.is_monitoring:
            return
        
        self.is_monitoring = False
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        
        logger.info("ğŸ“Š æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    async def _monitor_loop(self, interval: float):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                await self._collect_system_metrics()
                
                # åˆ†ææ€§èƒ½è¶‹åŠ¿
                await self._analyze_performance_trends()
                
                # æ£€æµ‹æ€§èƒ½é—®é¢˜
                await self._detect_performance_issues()
                
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½ç›‘æ§å‡ºé”™: {e}")
                await asyncio.sleep(interval)
    
    async def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        if not PSUTIL_AVAILABLE:
            # å¦‚æœpsutilä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            snapshot = SystemSnapshot(
                timestamp=time.time(),
                cpu_percent=0.0,
                memory_percent=0.0,
                memory_used_mb=0.0,
                disk_io_read_mb=0.0,
                disk_io_write_mb=0.0,
                network_sent_mb=0.0,
                network_recv_mb=0.0,
                active_threads=1,
                open_files=0
            )
            self.system_snapshots.append(snapshot)
            return
        
        try:
            # CPUå’Œå†…å­˜
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            # ç£ç›˜IO
            disk_io = psutil.disk_io_counters()
            disk_read_mb = disk_io.read_bytes / 1024 / 1024 if disk_io else 0
            disk_write_mb = disk_io.write_bytes / 1024 / 1024 if disk_io else 0
            
            # ç½‘ç»œIO
            network_io = psutil.net_io_counters()
            network_sent_mb = network_io.bytes_sent / 1024 / 1024 if network_io else 0
            network_recv_mb = network_io.bytes_recv / 1024 / 1024 if network_io else 0
            
            # è¿›ç¨‹ä¿¡æ¯
            process = psutil.Process()
            active_threads = process.num_threads()
            open_files = len(process.open_files())
            
            # åˆ›å»ºç³»ç»Ÿå¿«ç…§
            snapshot = SystemSnapshot(
                timestamp=time.time(),
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                memory_used_mb=memory.used / 1024 / 1024,
                disk_io_read_mb=disk_read_mb,
                disk_io_write_mb=disk_write_mb,
                network_sent_mb=network_sent_mb,
                network_recv_mb=network_recv_mb,
                active_threads=active_threads,
                open_files=open_files
            )
            
            self.system_snapshots.append(snapshot)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['peak_cpu_usage'] = max(self.stats['peak_cpu_usage'], cpu_percent)
            self.stats['peak_memory_usage'] = max(self.stats['peak_memory_usage'], memory.percent)
            
            # è®°å½•å…³é”®æŒ‡æ ‡
            self._record_metric("cpu_percent", cpu_percent, "percent", "system")
            self._record_metric("memory_percent", memory.percent, "percent", "system")
            self._record_metric("active_threads", active_threads, "count", "system")
            
        except Exception as e:
            logger.debug(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
    
    def _record_metric(self, name: str, value: float, unit: str, category: str, details: Dict = None):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        metric = PerformanceMetric(
            timestamp=time.time(),
            metric_name=name,
            value=value,
            unit=unit,
            category=category,
            details=details or {}
        )
        
        self.metrics_history.append(metric)
        self.current_metrics[name] = metric
    
    async def record_crawler_performance(self, performance: CrawlerPerformance):
        """è®°å½•çˆ¬è™«æ€§èƒ½æ•°æ®"""
        self.crawler_performances.append(performance)
        self.stats['total_monitored_tasks'] += 1
        
        # æ›´æ–°å¹³å‡ä»»åŠ¡æŒç»­æ—¶é—´
        duration = performance.end_time - performance.start_time
        if self.stats['total_monitored_tasks'] == 1:
            self.stats['avg_task_duration'] = duration
        else:
            # ç§»åŠ¨å¹³å‡
            alpha = 0.1
            self.stats['avg_task_duration'] = (
                alpha * duration + (1 - alpha) * self.stats['avg_task_duration']
            )
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self._record_metric("task_duration", duration, "seconds", "crawler", {
            "task_id": performance.task_id,
            "keyword": performance.keyword,
            "city": performance.city
        })
        
        self._record_metric("success_rate", performance.success_rate, "percent", "crawler")
        self._record_metric("cache_hit_rate", performance.cache_hit_rate, "percent", "crawler")
        
        # åˆ†æç“¶é¢ˆ
        bottlenecks = await self.bottleneck_detector.analyze_crawler_performance(performance)
        if bottlenecks:
            logger.warning(f"ğŸš¨ æ£€æµ‹åˆ°æ€§èƒ½ç“¶é¢ˆ: {', '.join(bottlenecks)}")
    
    async def _analyze_performance_trends(self):
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        if len(self.system_snapshots) < 5:
            return
        
        recent_snapshots = list(self.system_snapshots)[-5:]
        
        # CPUè¶‹åŠ¿åˆ†æ
        cpu_values = [s.cpu_percent for s in recent_snapshots]
        cpu_trend = self.trend_analyzer.analyze_trend(cpu_values)
        
        if cpu_trend == "increasing" and cpu_values[-1] > 70:
            self._trigger_alert("cpu_high_trend", "CPUä½¿ç”¨ç‡æŒç»­ä¸Šå‡")
        
        # å†…å­˜è¶‹åŠ¿åˆ†æ
        memory_values = [s.memory_percent for s in recent_snapshots]
        memory_trend = self.trend_analyzer.analyze_trend(memory_values)
        
        if memory_trend == "increasing" and memory_values[-1] > 80:
            self._trigger_alert("memory_high_trend", "å†…å­˜ä½¿ç”¨ç‡æŒç»­ä¸Šå‡")
    
    async def _detect_performance_issues(self):
        """æ£€æµ‹æ€§èƒ½é—®é¢˜"""
        if not self.current_metrics:
            return
        
        # æ£€æŸ¥é˜ˆå€¼
        for metric_name, threshold in self.alert_thresholds.items():
            if metric_name in self.current_metrics:
                current_value = self.current_metrics[metric_name].value
                
                if current_value > threshold:
                    self._trigger_alert(
                        f"{metric_name}_threshold",
                        f"{metric_name} è¶…è¿‡é˜ˆå€¼: {current_value:.2f} > {threshold}"
                    )
        
        # æ£€æŸ¥çˆ¬è™«æ€§èƒ½å¼‚å¸¸
        if len(self.crawler_performances) >= 3:
            recent_performances = list(self.crawler_performances)[-3:]
            
            # æ£€æŸ¥æˆåŠŸç‡ä¸‹é™
            success_rates = [p.success_rate for p in recent_performances]
            if all(rate < 0.7 for rate in success_rates):
                self._trigger_alert("low_success_rate", "æœ€è¿‘3æ¬¡ä»»åŠ¡æˆåŠŸç‡éƒ½ä½äº70%")
            
            # æ£€æŸ¥å“åº”æ—¶é—´å¼‚å¸¸
            load_times = [p.avg_page_load_time for p in recent_performances]
            avg_load_time = sum(load_times) / len(load_times)
            if avg_load_time > 20:
                self._trigger_alert("slow_page_load", f"å¹³å‡é¡µé¢åŠ è½½æ—¶é—´è¿‡é•¿: {avg_load_time:.2f}s")
    
    def _trigger_alert(self, alert_type: str, message: str):
        """è§¦å‘æ€§èƒ½è­¦æŠ¥"""
        self.stats['total_alerts'] += 1
        logger.warning(f"ğŸš¨ æ€§èƒ½è­¦æŠ¥ [{alert_type}]: {message}")
        
        # è®°å½•è­¦æŠ¥æŒ‡æ ‡
        self._record_metric(f"alert_{alert_type}", 1, "count", "alert", {
            "message": message,
            "alert_type": alert_type
        })
    
    def get_current_performance(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ€§èƒ½çŠ¶æ€"""
        latest_snapshot = self.system_snapshots[-1] if self.system_snapshots else None
        
        current_performance = {
            "timestamp": time.time(),
            "monitoring_active": self.is_monitoring,
            "system": {},
            "crawler": {},
            "alerts": [],
            "performance_score": self._calculate_performance_score()
        }
        
        if latest_snapshot:
            current_performance["system"] = {
                "cpu_percent": latest_snapshot.cpu_percent,
                "memory_percent": latest_snapshot.memory_percent,
                "memory_used_mb": latest_snapshot.memory_used_mb,
                "active_threads": latest_snapshot.active_threads,
                "open_files": latest_snapshot.open_files
            }
        
        # çˆ¬è™«æ€§èƒ½ç»Ÿè®¡
        if self.crawler_performances:
            recent_performances = list(self.crawler_performances)[-10:]
            current_performance["crawler"] = {
                "avg_success_rate": sum(p.success_rate for p in recent_performances) / len(recent_performances),
                "avg_page_load_time": sum(p.avg_page_load_time for p in recent_performances) / len(recent_performances),
                "avg_extraction_time": sum(p.avg_extraction_time for p in recent_performances) / len(recent_performances),
                "total_tasks": len(recent_performances)
            }
        
        # æœ€è¿‘çš„è­¦æŠ¥
        recent_alerts = [
            m for m in self.metrics_history 
            if m.category == "alert" and time.time() - m.timestamp < 300  # æœ€è¿‘5åˆ†é’Ÿ
        ]
        current_performance["alerts"] = [
            {"type": m.details.get("alert_type"), "message": m.details.get("message"), "time": m.timestamp}
            for m in recent_alerts
        ]
        
        return current_performance
    
    def _calculate_performance_score(self) -> float:
        """è®¡ç®—ç»¼åˆæ€§èƒ½è¯„åˆ† (0-100)"""
        score = 100.0
        
        # ç³»ç»Ÿèµ„æºä½¿ç”¨æ‰£åˆ†
        if self.system_snapshots:
            latest = self.system_snapshots[-1]
            
            if latest.cpu_percent > 80:
                score -= 20
            elif latest.cpu_percent > 60:
                score -= 10
            
            if latest.memory_percent > 85:
                score -= 20
            elif latest.memory_percent > 70:
                score -= 10
        
        # çˆ¬è™«æ€§èƒ½æ‰£åˆ†
        if self.crawler_performances:
            recent_performances = list(self.crawler_performances)[-5:]
            
            avg_success_rate = sum(p.success_rate for p in recent_performances) / len(recent_performances)
            if avg_success_rate < 0.5:
                score -= 30
            elif avg_success_rate < 0.7:
                score -= 15
            
            avg_load_time = sum(p.avg_page_load_time for p in recent_performances) / len(recent_performances)
            if avg_load_time > 20:
                score -= 15
            elif avg_load_time > 10:
                score -= 8
        
        # è­¦æŠ¥æ‰£åˆ†
        recent_alert_count = len([
            m for m in self.metrics_history 
            if m.category == "alert" and time.time() - m.timestamp < 600  # æœ€è¿‘10åˆ†é’Ÿ
        ])
        score -= min(20, recent_alert_count * 2)
        
        return max(0.0, score)
    
    def get_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        cutoff_time = time.time() - hours * 3600
        
        # ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
        relevant_snapshots = [s for s in self.system_snapshots if s.timestamp > cutoff_time]
        relevant_performances = [p for p in self.crawler_performances if p.start_time > cutoff_time]
        relevant_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
        
        report = {
            "report_period": f"æœ€è¿‘{hours}å°æ—¶",
            "generated_at": time.time(),
            "summary": {
                "total_tasks": len(relevant_performances),
                "avg_success_rate": 0.0,
                "avg_response_time": 0.0,
                "peak_cpu": 0.0,
                "peak_memory": 0.0,
                "total_alerts": len([m for m in relevant_metrics if m.category == "alert"])
            },
            "trends": {},
            "bottlenecks": [],
            "recommendations": []
        }
        
        if relevant_performances:
            report["summary"]["avg_success_rate"] = sum(p.success_rate for p in relevant_performances) / len(relevant_performances)
            report["summary"]["avg_response_time"] = sum(p.avg_page_load_time for p in relevant_performances) / len(relevant_performances)
        
        if relevant_snapshots:
            report["summary"]["peak_cpu"] = max(s.cpu_percent for s in relevant_snapshots)
            report["summary"]["peak_memory"] = max(s.memory_percent for s in relevant_snapshots)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        report["recommendations"] = self._generate_recommendations(report["summary"])
        
        return report
    
    def _generate_recommendations(self, summary: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # CPUä¼˜åŒ–å»ºè®®
        if summary.get("peak_cpu", 0) > 80:
            recommendations.append("CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å‡å°‘å¹¶å‘ä»»åŠ¡æ•°é‡æˆ–ä¼˜åŒ–çˆ¬è™«é€»è¾‘")
        
        # å†…å­˜ä¼˜åŒ–å»ºè®®
        if summary.get("peak_memory", 0) > 85:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å¢åŠ å†…å­˜æ¸…ç†é€»è¾‘æˆ–å‡å°‘ç¼“å­˜å¤§å°")
        
        # æˆåŠŸç‡ä¼˜åŒ–å»ºè®®
        if summary.get("avg_success_rate", 1.0) < 0.7:
            recommendations.append("ä»»åŠ¡æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥ã€é€‰æ‹©å™¨é…ç½®æˆ–å¢åŠ é‡è¯•æœºåˆ¶")
        
        # å“åº”æ—¶é—´ä¼˜åŒ–å»ºè®®
        if summary.get("avg_response_time", 0) > 15:
            recommendations.append("é¡µé¢åŠ è½½æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œé…ç½®æˆ–å¢åŠ è¶…æ—¶è®¾ç½®")
        
        # è­¦æŠ¥å»ºè®®
        if summary.get("total_alerts", 0) > 10:
            recommendations.append("è­¦æŠ¥æ•°é‡è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®å’Œçˆ¬è™«ç¨³å®šæ€§")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œæ— éœ€ç‰¹æ®Šä¼˜åŒ–")
        
        return recommendations
    
    def get_detailed_stats(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "monitor_stats": self.stats.copy(),
            "system_snapshots_count": len(self.system_snapshots),
            "crawler_performances_count": len(self.crawler_performances),
            "metrics_history_count": len(self.metrics_history),
            "current_performance_score": self._calculate_performance_score(),
            "monitoring_active": self.is_monitoring
        }


class BottleneckDetector:
    """ç“¶é¢ˆæ£€æµ‹å™¨"""
    
    async def analyze_crawler_performance(self, performance: CrawlerPerformance) -> List[str]:
        """åˆ†æçˆ¬è™«æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []
        
        # é¡µé¢åŠ è½½ç“¶é¢ˆ
        if performance.avg_page_load_time > 15:
            bottlenecks.append("é¡µé¢åŠ è½½ç¼“æ…¢")
        
        # æ•°æ®æå–ç“¶é¢ˆ
        if performance.avg_extraction_time > 10:
            bottlenecks.append("æ•°æ®æå–è€—æ—¶")
        
        # é‡è¯•è¿‡å¤š
        if performance.retry_count > 5:
            bottlenecks.append("é‡è¯•æ¬¡æ•°è¿‡å¤š")
        
        # æˆåŠŸç‡ä½
        if performance.success_rate < 0.7:
            bottlenecks.append("æˆåŠŸç‡ä½")
        
        # ç¼“å­˜å‘½ä¸­ç‡ä½
        if performance.cache_hit_rate < 0.3:
            bottlenecks.append("ç¼“å­˜æ•ˆç‡ä½")
        
        return bottlenecks


class TrendAnalyzer:
    """è¶‹åŠ¿åˆ†æå™¨"""
    
    def analyze_trend(self, values: List[float]) -> str:
        """åˆ†æè¶‹åŠ¿ï¼šincreasing, decreasing, stable"""
        if len(values) < 3:
            return "stable"
        
        # ç®€å•çº¿æ€§è¶‹åŠ¿åˆ†æ
        diff_sum = sum(values[i+1] - values[i] for i in range(len(values)-1))
        
        if diff_sum > len(values) * 0.5:
            return "increasing"
        elif diff_sum < -len(values) * 0.5:
            return "decreasing"
        else:
            return "stable"