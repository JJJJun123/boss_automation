#!/usr/bin/env python3
"""
Bossç›´è˜è‡ªåŠ¨åŒ–æ±‚èŒç³»ç»Ÿ - Webç‰ˆæœ¬
æ”¯æŒçµæ´»çš„é…ç½®ç®¡ç†å’ŒWebç•Œé¢
"""

import os
import sys
import logging
import json
from datetime import datetime
from crawler.boss_spider import BossSpider
from analyzer.job_analyzer import JobAnalyzer
from config.config_manager import ConfigManager


def print_header():
    """æ‰“å°ç¨‹åºå¤´éƒ¨ä¿¡æ¯"""
    print("=" * 60)
    print("ğŸ¤– Bossç›´è˜è‡ªåŠ¨åŒ–æ±‚èŒç³»ç»Ÿ - MVPç‰ˆæœ¬")
    print("=" * 60)
    print(f"â° å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()


def print_job_analysis(job, index):
    """æ‰“å°å•ä¸ªå²—ä½åˆ†æç»“æœ - å¢å¼ºç‰ˆæœ¬"""
    analysis = job.get('analysis', {})
    score = analysis.get('score', 0)
    
    print(f"\nğŸ“‹ å²—ä½ #{index}")
    print(f"ğŸ¢ å…¬å¸: {job.get('company', 'æœªçŸ¥')}")
    print(f"ğŸ’¼ èŒä½: {job.get('title', 'æœªçŸ¥')}")
    print(f"ğŸ’° è–ªèµ„: {job.get('salary', 'æœªçŸ¥')}")
    print(f"ğŸ·ï¸  æ ‡ç­¾: {', '.join(job.get('tags', []))}")
    print(f"ğŸ“ é“¾æ¥: {job.get('url', 'æœªçŸ¥')}")
    
    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if job.get('work_location'):
        print(f"ğŸŒ å·¥ä½œåœ°ç‚¹: {job.get('work_location')}")
    if job.get('benefits'):
        print(f"ğŸ ç¦åˆ©å¾…é‡: {job.get('benefits')}")
    if job.get('experience_required'):
        print(f"ğŸ“Š ç»éªŒè¦æ±‚: {job.get('experience_required')}")
    
    # AIåˆ†æç»“æœ
    print(f"â­ AIè¯„åˆ†: {score}/10 ({analysis.get('recommendation', 'æœªçŸ¥')})")
    print(f"ğŸ’¡ åˆ†æ: {analysis.get('summary', 'æ— åˆ†æç»“æœ')}")
    reason = analysis.get('reason', 'æ— è¯¦ç»†ç†ç”±')
    print(f"ğŸ“ ç†ç”±: {reason[:100]}..." if len(reason) > 100 else f"ğŸ“ ç†ç”±: {reason}")
    
    # æ˜¾ç¤ºèŒä½æè¿°ç‰‡æ®µï¼ˆå¦‚æœæœ‰ï¼‰
    if job.get('job_description'):
        desc = job.get('job_description', '')
        if len(desc) > 150:
            print(f"ğŸ“„ èŒä½æè¿°: {desc[:150]}...")
        else:
            print(f"ğŸ“„ èŒä½æè¿°: {desc}")
    
    print("-" * 50)


def save_results_to_file(jobs, filename="data/job_results.txt"):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    try:
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"Bossç›´è˜å²—ä½åˆ†æç»“æœ\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å…±æ‰¾åˆ° {len(jobs)} ä¸ªåˆé€‚å²—ä½\n")
            f.write("=" * 80 + "\n\n")
            
            for i, job in enumerate(jobs, 1):
                analysis = job.get('analysis', {})
                f.write(f"å²—ä½ #{i}\n")
                f.write(f"å…¬å¸: {job.get('company', 'æœªçŸ¥')}\n")
                f.write(f"èŒä½: {job.get('title', 'æœªçŸ¥')}\n")
                f.write(f"è–ªèµ„: {job.get('salary', 'æœªçŸ¥')}\n")
                f.write(f"æ ‡ç­¾: {', '.join(job.get('tags', []))}\n")
                f.write(f"å…¬å¸ä¿¡æ¯: {job.get('company_info', 'æœªçŸ¥')}\n")
                f.write(f"é“¾æ¥: {job.get('url', 'æœªçŸ¥')}\n")
                
                # è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if job.get('work_location'):
                    f.write(f"å·¥ä½œåœ°ç‚¹: {job.get('work_location')}\n")
                if job.get('benefits'):
                    f.write(f"ç¦åˆ©å¾…é‡: {job.get('benefits')}\n")
                if job.get('experience_required'):
                    f.write(f"ç»éªŒè¦æ±‚: {job.get('experience_required')}\n")
                if job.get('company_details'):
                    f.write(f"å…¬å¸è¯¦æƒ…: {job.get('company_details')}\n")
                if job.get('job_requirements'):
                    f.write(f"å²—ä½è¦æ±‚: {job.get('job_requirements')}\n")
                
                # AIåˆ†æç»“æœ
                f.write(f"AIè¯„åˆ†: {analysis.get('score', 0)}/10\n")
                f.write(f"æ¨èçŠ¶æ€: {analysis.get('recommendation', 'æœªçŸ¥')}\n")
                f.write(f"åˆ†ææ‘˜è¦: {analysis.get('summary', 'æ— æ‘˜è¦')}\n")
                f.write(f"è¯¦ç»†ç†ç”±: {analysis.get('reason', 'æ— è¯¦ç»†ç†ç”±')}\n")
                
                # å®Œæ•´èŒä½æè¿°
                if job.get('job_description'):
                    f.write(f"\nèŒä½æè¿°:\n{job.get('job_description')}\n")
                
                f.write("-" * 80 + "\n\n")
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        return False


def save_results_to_json(jobs, filename="data/job_results.json"):
    """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # æ„å»ºJSONæ•°æ®ç»“æ„
        json_data = {
            "metadata": {
                "generated_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "total_jobs": len(jobs),
                "version": "1.0.0"
            },
            "jobs": jobs
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSONç»“æœå·²ä¿å­˜åˆ°: {filename}")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜JSONç»“æœå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print_header()
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    try:
        config_manager = ConfigManager()
        
        # éªŒè¯é…ç½®
        if not config_manager.validate_config():
            print("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")
            print("ğŸ“ è¯·ç¡®ä¿æ­£ç¡®è®¾ç½®äº†APIå¯†é’¥å’ŒåŸºæœ¬é…ç½®")
            return
        
        # è·å–æœç´¢é…ç½®
        search_config = config_manager.get_search_config()
        ai_config = config_manager.get_ai_config()
        
        # è·å–ç¬¬ä¸€ä¸ªåŸå¸‚çš„ä»£ç ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        selected_cities = search_config['cities']
        city_codes = search_config['city_codes']
        
        if not selected_cities:
            print("âŒ æœªé€‰æ‹©ä»»ä½•åŸå¸‚")
            return
        
        # è·å–ç¬¬ä¸€ä¸ªåŸå¸‚çš„ä»£ç 
        first_city = selected_cities[0]
        city_code = city_codes.get(first_city, {}).get('code', '101210100')
        city_name = city_codes.get(first_city, {}).get('name', 'æœªçŸ¥åŸå¸‚')
        
        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        print(f"ğŸ” æœç´¢å…³é”®è¯: {search_config['keyword']}")
        print(f"ğŸ“ æœç´¢åŸå¸‚: {city_name} ({city_code})")
        print(f"ğŸ“Š æœ€å¤§æœç´¢å²—ä½æ•°: {search_config['max_jobs']}")
        print(f"ğŸ¤– AIåˆ†æå²—ä½æ•°: {search_config['max_analyze_jobs']}")
        print(f"â­ æœ€ä½è¯„åˆ†: {ai_config['min_score']}/10")
        print(f"ğŸ¤– AIæ¨¡å‹: {ai_config['provider'].upper()}")
        print(f"ğŸ“„ è·å–è¯¦ç»†ä¿¡æ¯: {'æ˜¯' if search_config['fetch_details'] else 'å¦'}")
        print()
        
    except Exception as e:
        print(f"âŒ é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")
        logging.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    spider = None
    try:
        # 1. å¯åŠ¨çˆ¬è™«
        print("ğŸš€ ç¬¬ä¸€æ­¥: å¯åŠ¨çˆ¬è™«...")
        spider = BossSpider()
        if not spider.start():
            print("âŒ çˆ¬è™«å¯åŠ¨å¤±è´¥")
            return
        
        # 2. ç™»å½•
        print("\nğŸ” ç¬¬äºŒæ­¥: å¤„ç†ç™»å½•...")
        if not spider.login_with_manual_help():
            print("âŒ ç™»å½•å¤±è´¥")
            return
        
        # 3. æœç´¢å²—ä½
        print(f"\nğŸ” ç¬¬ä¸‰æ­¥: æœç´¢å²—ä½...")
        jobs = spider.search_jobs(search_config['keyword'], city_code, search_config['max_jobs'], search_config['fetch_details'])
        
        if not jobs:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å²—ä½")
            return
        
        # 4. AIåˆ†æ
        print(f"\nğŸ¤– ç¬¬å››æ­¥: AIæ™ºèƒ½åˆ†æ...")
        analyzer = JobAnalyzer(ai_config['provider'])
        
        # åªåˆ†æå‰max_analyze_jobsä¸ªå²—ä½
        jobs_to_analyze = jobs[:search_config['max_analyze_jobs']]
        print(f"å‡†å¤‡åˆ†æå‰ {len(jobs_to_analyze)} ä¸ªå²—ä½ (å…±æ‰¾åˆ° {len(jobs)} ä¸ª)")
        
        analyzed_jobs = analyzer.analyze_jobs(jobs_to_analyze)
        
        # 5. è¿‡æ»¤å’Œæ’åº
        print(f"\nğŸ¯ ç¬¬äº”æ­¥: è¿‡æ»¤å’Œæ’åº...")
        filtered_jobs = analyzer.filter_and_sort_jobs(analyzed_jobs, ai_config['min_score'])
        
        # 6. è¾“å‡ºç»“æœ
        print(f"\nğŸ“Š ç¬¬å…­æ­¥: è¾“å‡ºç»“æœ...")
        if filtered_jobs:
            print(f"\nğŸ‰ æ‰¾åˆ° {len(filtered_jobs)} ä¸ªåŒ¹é…çš„å²—ä½:")
            
            for i, job in enumerate(filtered_jobs, 1):
                print_job_analysis(job, i)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            save_results_to_file(filtered_jobs)
            save_results_to_json(filtered_jobs)
            
        else:
            print("ğŸ˜” å¾ˆé—æ†¾ï¼Œæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„å²—ä½")
            print("ğŸ’¡ å»ºè®®:")
            print("   - é™ä½æœ€ä½è¯„åˆ†æ ‡å‡†")
            print("   - å°è¯•å…¶ä»–æœç´¢å…³é”®è¯")
            print("   - æ£€æŸ¥ç”¨æˆ·è¦æ±‚è®¾ç½®")
        
        print(f"\nâœ… ä»»åŠ¡å®Œæˆ! ç”¨æ—¶: {datetime.now()}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        if spider:
            print("\nğŸ§¹ æ¸…ç†èµ„æº...")
            spider.close()
        print("ğŸ‘‹ ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()