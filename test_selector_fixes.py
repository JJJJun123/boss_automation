#!/usr/bin/env python3
"""
æµ‹è¯•é€‰æ‹©å™¨ä¿®å¤æ•ˆæœ
éªŒè¯æ–°çš„é€‰æ‹©å™¨å’Œè¿‡æ»¤é€»è¾‘æ˜¯å¦èƒ½æ­£ç¡®æå–å²—ä½ä¿¡æ¯
"""

import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def test_selector_fixes():
    """æµ‹è¯•ä¿®å¤åçš„é€‰æ‹©å™¨æ•ˆæœ"""
    try:
        from crawler.real_playwright_spider import RealPlaywrightBossSpider
        
        logger.info("ğŸ” æµ‹è¯•ä¿®å¤åçš„é€‰æ‹©å™¨æ•ˆæœ...")
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹ï¼ˆå¯è§æ¨¡å¼ï¼Œä¾¿äºè§‚å¯Ÿï¼‰
        spider = RealPlaywrightBossSpider(headless=False)
        
        if not await spider.start():
            logger.error("âŒ æ— æ³•å¯åŠ¨Playwright")
            return False
        
        # æµ‹è¯•æœç´¢ - ä½¿ç”¨ä¿®æ­£åçš„åŸå¸‚ä»£ç 
        keyword = "é£é™©ç®¡ç†"
        city = "shanghai"  # ç°åœ¨åº”è¯¥æ­£ç¡®æ˜ å°„åˆ°ä¸Šæµ·
        
        logger.info(f"ğŸ” æœç´¢æµ‹è¯•: {keyword} åœ¨ {city}")
        logger.info(f"ğŸ“ åŸå¸‚ä»£ç : {spider.city_codes[city]}")
        
        # æ‰§è¡Œæœç´¢
        jobs = await spider.search_jobs(keyword, city, 5)
        
        if jobs:
            logger.info(f"âœ… æˆåŠŸæå–åˆ° {len(jobs)} ä¸ªå²—ä½")
            
            # åˆ†ææå–çš„å²—ä½è´¨é‡
            for i, job in enumerate(jobs, 1):
                logger.info(f"\n{'='*40}")
                logger.info(f"ğŸ“‹ å²—ä½ {i} è¯¦ç»†ä¿¡æ¯:")
                logger.info(f"   æ ‡é¢˜: {job.get('title', 'N/A')}")
                logger.info(f"   å…¬å¸: {job.get('company', 'N/A')}")
                logger.info(f"   åœ°ç‚¹: {job.get('work_location', 'N/A')}")
                logger.info(f"   è–ªèµ„: {job.get('salary', 'N/A')}")
                logger.info(f"   é“¾æ¥: {job.get('url', 'N/A')[:60]}...")
                
                # éªŒè¯æ•°æ®è´¨é‡
                quality_checks = []
                if job.get('title') and job.get('title') != 'æœªçŸ¥':
                    quality_checks.append("âœ… æ ‡é¢˜æœ‰æ•ˆ")
                else:
                    quality_checks.append("âŒ æ ‡é¢˜ç¼ºå¤±")
                    
                if job.get('company') and job.get('company') not in ['æœªçŸ¥å…¬å¸', 'æœªçŸ¥']:
                    quality_checks.append("âœ… å…¬å¸æœ‰æ•ˆ")
                else:
                    quality_checks.append("âŒ å…¬å¸ç¼ºå¤±")
                    
                if job.get('work_location') and job.get('work_location') not in ['æœªçŸ¥åœ°ç‚¹', 'æœªçŸ¥']:
                    quality_checks.append("âœ… åœ°ç‚¹æœ‰æ•ˆ")
                else:
                    quality_checks.append("âŒ åœ°ç‚¹ç¼ºå¤±")
                    
                if job.get('salary') and job.get('salary') != 'é¢è®®':
                    quality_checks.append("âœ… è–ªèµ„æœ‰æ•ˆ")
                else:
                    quality_checks.append("âš ï¸ è–ªèµ„å¾…è®®")
                    
                if job.get('url') and job.get('url').startswith('http'):
                    quality_checks.append("âœ… é“¾æ¥æœ‰æ•ˆ")
                else:
                    quality_checks.append("âŒ é“¾æ¥ç¼ºå¤±")
                
                logger.info(f"   è´¨é‡è¯„ä¼°: {' | '.join(quality_checks)}")
            
            # æ•´ä½“è¯„ä¼°
            valid_jobs = sum(1 for job in jobs if 
                           job.get('company') not in ['æœªçŸ¥å…¬å¸', 'æœªçŸ¥', None] and
                           job.get('work_location') not in ['æœªçŸ¥åœ°ç‚¹', 'æœªçŸ¥', None])
            
            success_rate = valid_jobs / len(jobs) * 100 if jobs else 0
            
            logger.info(f"\nğŸ“Š æ•´ä½“è¯„ä¼°:")
            logger.info(f"   æ€»å²—ä½æ•°: {len(jobs)}")
            logger.info(f"   æœ‰æ•ˆå²—ä½: {valid_jobs}")
            logger.info(f"   æˆåŠŸç‡: {success_rate:.1f}%")
            
            if success_rate >= 80:
                logger.info("ğŸ‰ ä¿®å¤æ•ˆæœä¼˜ç§€ï¼")
            elif success_rate >= 60:
                logger.info("âœ… ä¿®å¤æ•ˆæœè‰¯å¥½ï¼Œæœ‰æ‰€æ”¹å–„")
            else:
                logger.warning("âš ï¸ ä¿®å¤æ•ˆæœæœ‰é™ï¼Œä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
            
            # æµ‹è¯•åŸå¸‚åŒ¹é…
            shanghai_jobs = sum(1 for job in jobs if 
                              job.get('work_location') and 'ä¸Šæµ·' in job.get('work_location'))
            
            if shanghai_jobs > 0:
                logger.info(f"âœ… åŸå¸‚ä»£ç ä¿®å¤æˆåŠŸï¼š{shanghai_jobs}/{len(jobs)} ä¸ªå²—ä½åœ¨ä¸Šæµ·")
            else:
                logger.warning("âš ï¸ åŸå¸‚ä»£ç å¯èƒ½ä»æœ‰é—®é¢˜ï¼šæœªæ‰¾åˆ°ä¸Šæµ·å²—ä½")
                
        else:
            logger.warning("âš ï¸ æœªæå–åˆ°ä»»ä½•å²—ä½")
            success_rate = 0
        
        await spider.close()
        return success_rate >= 60
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Bossç›´è˜é€‰æ‹©å™¨ä¿®å¤æµ‹è¯•")
    print("=" * 50)
    print("æœ¬æµ‹è¯•å°†éªŒè¯ä»¥ä¸‹ä¿®å¤:")
    print("1. âœ… åŸå¸‚ä»£ç ä¿®æ­£ï¼ˆä¸Šæµ·ã€æ­å·ï¼‰")
    print("2. ğŸ” ç²¾ç¡®çš„å²—ä½é€‰æ‹©å™¨")
    print("3. ğŸ¢ ä¼˜åŒ–çš„å…¬å¸åç§°æå–")
    print("4. ğŸ’° æ”¹è¿›çš„è–ªèµ„ä¿¡æ¯å¤„ç†")
    print("5. ğŸ“ æ™ºèƒ½çš„åœ°ç‚¹ä¿¡æ¯æå–")
    print("6. ğŸš« æ— æ•ˆå…ƒç´ è¿‡æ»¤")
    print()
    
    success = asyncio.run(test_selector_fixes())
    
    if success:
        print("\nğŸ‰ æµ‹è¯•é€šè¿‡ï¼é€‰æ‹©å™¨ä¿®å¤æ•ˆæœè‰¯å¥½")
        print("ğŸ’¡ å»ºè®®ç°åœ¨è¿è¡Œå®Œæ•´åº”ç”¨è¿›è¡ŒéªŒè¯: python run_web.py")
    else:
        print("\nâŒ æµ‹è¯•æœªé€šè¿‡ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        print("ğŸ’¡ è¯·æŸ¥çœ‹æ—¥å¿—ä¿¡æ¯åˆ†æå…·ä½“é—®é¢˜")


if __name__ == "__main__":
    main()