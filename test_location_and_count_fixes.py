#!/usr/bin/env python3
"""
æµ‹è¯•åœ°ç‚¹åŒ¹é…å’Œå²—ä½æ•°é‡ä¿®å¤æ•ˆæœ
éªŒè¯ï¼š
1. åŸå¸‚ä»£ç æ˜ å°„æ˜¯å¦æ­£ç¡®
2. åœ°ç‚¹ä¿¡æ¯æ˜¯å¦ä¸é€‰æ‹©åŒ¹é…
3. å²—ä½æ•°é‡æ˜¯å¦æ­£å¸¸
4. URLæ˜¯å¦æ­£ç¡®ç”Ÿæˆ
"""

import logging
import sys
import os
import asyncio
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def test_city_code_mapping():
    """æµ‹è¯•åŸå¸‚ä»£ç æ˜ å°„çš„æ­£ç¡®æ€§"""
    logger.info("ğŸ™ï¸ æµ‹è¯•åŸå¸‚ä»£ç æ˜ å°„")
    
    # é¢„æœŸçš„åŸå¸‚ä»£ç  (æ¥è‡ªapp_config.yaml)
    expected_mapping = {
        "shanghai": "101210100",   # ä¸Šæµ·
        "beijing": "101010100",    # åŒ—äº¬
        "shenzhen": "101280600",   # æ·±åœ³
        "hangzhou": "101210300"    # æ­å·
    }
    
    try:
        # æµ‹è¯•real_playwright_spiderä¸­çš„æ˜ å°„
        from crawler.real_playwright_spider import RealPlaywrightBossSpider
        spider = RealPlaywrightBossSpider()
        
        all_correct = True
        for city_name, expected_code in expected_mapping.items():
            actual_code = spider.city_codes.get(city_name)
            if actual_code == expected_code:
                logger.info(f"   âœ… {city_name}: {actual_code} (æ­£ç¡®)")
            else:
                logger.error(f"   âŒ {city_name}: æœŸæœ› {expected_code}, å®é™… {actual_code}")
                all_correct = False
        
        # æµ‹è¯•playwright_spiderä¸­çš„åå‘æ˜ å°„
        from crawler.playwright_spider import _get_city_name_by_code
        
        reverse_mapping = {
            "101210100": "ä¸Šæµ·",
            "101010100": "åŒ—äº¬", 
            "101280600": "æ·±åœ³",
            "101210300": "æ­å·"
        }
        
        for code, expected_name in reverse_mapping.items():
            actual_name = _get_city_name_by_code(code)
            if actual_name == expected_name:
                logger.info(f"   âœ… ä»£ç  {code}: {actual_name} (æ­£ç¡®)")
            else:
                logger.error(f"   âŒ ä»£ç  {code}: æœŸæœ› {expected_name}, å®é™… {actual_name}")
                all_correct = False
        
        return all_correct
        
    except Exception as e:
        logger.error(f"âŒ åŸå¸‚ä»£ç æ˜ å°„æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_url_generation():
    """æµ‹è¯•URLç”ŸæˆåŠŸèƒ½"""
    logger.info("ğŸ”— æµ‹è¯•URLç”ŸæˆåŠŸèƒ½")
    
    try:
        from crawler.playwright_spider import _generate_real_job_url
        
        # æµ‹è¯•ä¸åŒå²—ä½çš„URLç”Ÿæˆ
        test_cases = [
            ("æ•°æ®åˆ†æå¸ˆ", 0),
            ("å¸‚åœºé£é™©ç®¡ç†", 1),
            ("Pythonå¼€å‘", 2)
        ]
        
        all_correct = True
        for job_title, index in test_cases:
            url = _generate_real_job_url(job_title, index)
            
            # éªŒè¯URLæ ¼å¼
            if url.startswith("https://www.zhipin.com/job_detail/") and url.endswith(".html?lid=20T&city=101280600"):
                logger.info(f"   âœ… {job_title}: URLæ ¼å¼æ­£ç¡®")
                logger.info(f"      {url}")
            else:
                logger.error(f"   âŒ {job_title}: URLæ ¼å¼é”™è¯¯ - {url}")
                all_correct = False
        
        return all_correct
        
    except Exception as e:
        logger.error(f"âŒ URLç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_fallback_data_location():
    """æµ‹è¯•å¤‡ç”¨æ•°æ®çš„åœ°ç‚¹ä¿¡æ¯"""
    logger.info("ğŸ“ æµ‹è¯•å¤‡ç”¨æ•°æ®åœ°ç‚¹ä¿¡æ¯")
    
    try:
        from crawler.playwright_spider import _generate_fallback_data
        
        # æµ‹è¯•ä¸åŒåŸå¸‚çš„å¤‡ç”¨æ•°æ®
        test_cities = [
            ("101210100", "ä¸Šæµ·"),
            ("101010100", "åŒ—äº¬"),
            ("101280600", "æ·±åœ³"),
            ("101210300", "æ­å·")
        ]
        
        all_correct = True
        for city_code, expected_city_name in test_cities:
            jobs = _generate_fallback_data("æµ‹è¯•å²—ä½", 3, city_code)
            
            if jobs:
                first_job_location = jobs[0].get('work_location', '')
                if expected_city_name in first_job_location:
                    logger.info(f"   âœ… åŸå¸‚ä»£ç  {city_code}: åœ°ç‚¹ '{first_job_location}' åŒ…å« '{expected_city_name}'")
                else:
                    logger.error(f"   âŒ åŸå¸‚ä»£ç  {city_code}: åœ°ç‚¹ '{first_job_location}' ä¸åŒ…å« '{expected_city_name}'")
                    all_correct = False
            else:
                logger.error(f"   âŒ åŸå¸‚ä»£ç  {city_code}: æœªç”Ÿæˆå¤‡ç”¨æ•°æ®")
                all_correct = False
        
        return all_correct
        
    except Exception as e:
        logger.error(f"âŒ å¤‡ç”¨æ•°æ®åœ°ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_real_playwright_search():
    """æµ‹è¯•çœŸå®Playwrightæœç´¢(å¦‚æœå¯ç”¨)"""
    logger.info("ğŸ­ æµ‹è¯•çœŸå®Playwrightæœç´¢")
    
    try:
        from crawler.real_playwright_spider import RealPlaywrightBossSpider
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹(æ— å¤´æ¨¡å¼ç”¨äºæµ‹è¯•)
        spider = RealPlaywrightBossSpider(headless=True)
        
        # æµ‹è¯•å¯åŠ¨
        if not await spider.start():
            logger.warning("   âš ï¸ Playwrightå¯åŠ¨å¤±è´¥ï¼Œè·³è¿‡çœŸå®æœç´¢æµ‹è¯•")
            return True
        
        logger.info("   âœ… Playwrightå¯åŠ¨æˆåŠŸ")
        
        # æµ‹è¯•ä¸åŒåŸå¸‚çš„æœç´¢
        test_cases = [
            ("æ•°æ®åˆ†æ", "shanghai", "ä¸Šæµ·"),
            ("äº§å“ç»ç†", "beijing", "åŒ—äº¬")
        ]
        
        all_correct = True
        for keyword, city, expected_location in test_cases:
            logger.info(f"   ğŸ” æµ‹è¯•æœç´¢: {keyword} in {city}")
            
            try:
                jobs = await spider.search_jobs(keyword, city, 2)  # åªæœç´¢2ä¸ªé¿å…è€—æ—¶
                
                if jobs:
                    logger.info(f"      âœ… æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½")
                    
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªå²—ä½çš„åœ°ç‚¹ä¿¡æ¯
                    first_job = jobs[0]
                    job_location = first_job.get('work_location', '')
                    
                    logger.info(f"      å²—ä½: {first_job.get('title', 'æœªçŸ¥')}")
                    logger.info(f"      åœ°ç‚¹: {job_location}")
                    logger.info(f"      å…¬å¸: {first_job.get('company', 'æœªçŸ¥')}")
                    
                    # éªŒè¯åœ°ç‚¹æ˜¯å¦åŒ¹é…(å®½æ¾åŒ¹é…ï¼Œå› ä¸ºå¯èƒ½åŒ…å«åŒºåŸŸä¿¡æ¯)
                    if expected_location in job_location or job_location == "æœªçŸ¥":
                        logger.info(f"      âœ… åœ°ç‚¹åŒ¹é…æˆ–ä¸ºé»˜è®¤å€¼")
                    else:
                        logger.warning(f"      âš ï¸ åœ°ç‚¹å¯èƒ½ä¸åŒ¹é…: æœŸæœ›åŒ…å«'{expected_location}'ï¼Œå®é™…'{job_location}'")
                else:
                    logger.warning(f"      âš ï¸ æœªæ‰¾åˆ°å²—ä½ï¼Œå¯èƒ½æ˜¯ç½‘ç«™é™åˆ¶æˆ–é€‰æ‹©å™¨é—®é¢˜")
                    
            except Exception as e:
                logger.error(f"      âŒ æœç´¢å¤±è´¥: {e}")
                all_correct = False
        
        # å…³é—­æµè§ˆå™¨
        await spider.close()
        return all_correct
        
    except ImportError:
        logger.warning("   âš ï¸ Playwrightæœªå®‰è£…ï¼Œè·³è¿‡çœŸå®æœç´¢æµ‹è¯•")
        return True
    except Exception as e:
        logger.error(f"âŒ çœŸå®Playwrightæœç´¢æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_playwright_mcp_integration():
    """æµ‹è¯•Playwright MCPé›†æˆ"""
    logger.info("ğŸ”„ æµ‹è¯•Playwright MCPé›†æˆ")
    
    try:
        from crawler.playwright_spider import search_with_playwright_mcp
        
        # æµ‹è¯•ä¸åŒåŸå¸‚ä»£ç çš„æœç´¢
        test_cases = [
            ("101210100", "ä¸Šæµ·", "æ•°æ®åˆ†æ"),
            ("101010100", "åŒ—äº¬", "äº§å“ç»ç†"),
            ("101280600", "æ·±åœ³", "è½¯ä»¶å·¥ç¨‹å¸ˆ")
        ]
        
        all_correct = True
        for city_code, city_name, keyword in test_cases:
            logger.info(f"   ğŸ” æµ‹è¯•MCPæœç´¢: {keyword} åœ¨ {city_name} ({city_code})")
            
            try:
                jobs = search_with_playwright_mcp(keyword, city_code, 3, False)
                
                if jobs:
                    logger.info(f"      âœ… æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½")
                    
                    # æ£€æŸ¥å²—ä½ä¿¡æ¯
                    first_job = jobs[0]
                    logger.info(f"      å²—ä½: {first_job.get('title', 'æœªçŸ¥')}")
                    logger.info(f"      åœ°ç‚¹: {first_job.get('work_location', 'æœªçŸ¥')}")
                    logger.info(f"      å¼•æ“: {first_job.get('engine_source', 'æœªçŸ¥')}")
                    logger.info(f"      URL: {first_job.get('url', 'æœªçŸ¥')}")
                    
                    # éªŒè¯URLæ ¼å¼
                    url = first_job.get('url', '')
                    if 'job_detail' in url and '.html' in url:
                        logger.info(f"      âœ… URLæ ¼å¼æ­£ç¡®")
                    else:
                        logger.warning(f"      âš ï¸ URLæ ¼å¼å¯èƒ½å¼‚å¸¸")
                        
                    # éªŒè¯åœ°ç‚¹ä¿¡æ¯ 
                    location = first_job.get('work_location', '')
                    if city_name in location:
                        logger.info(f"      âœ… åœ°ç‚¹ä¿¡æ¯åŒ¹é…")
                    else:
                        logger.warning(f"      âš ï¸ åœ°ç‚¹ä¿¡æ¯å¯èƒ½ä¸åŒ¹é…: {location}")
                        
                else:
                    logger.warning(f"      âš ï¸ æœªæ‰¾åˆ°å²—ä½")
                    
            except Exception as e:
                logger.error(f"      âŒ MCPæœç´¢å¤±è´¥: {e}")
                all_correct = False
        
        return all_correct
        
    except Exception as e:
        logger.error(f"âŒ Playwright MCPé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•åœ°ç‚¹åŒ¹é…å’Œå²—ä½æ•°é‡ä¿®å¤æ•ˆæœ")
    logger.info("=" * 60)
    
    test_results = {}
    
    # 1. æµ‹è¯•åŸå¸‚ä»£ç æ˜ å°„
    test_results["åŸå¸‚ä»£ç æ˜ å°„"] = test_city_code_mapping()
    
    # 2. æµ‹è¯•URLç”Ÿæˆ
    test_results["URLç”Ÿæˆ"] = test_url_generation()
    
    # 3. æµ‹è¯•å¤‡ç”¨æ•°æ®åœ°ç‚¹
    test_results["å¤‡ç”¨æ•°æ®åœ°ç‚¹"] = test_fallback_data_location()
    
    # 4. æµ‹è¯•Playwright MCPé›†æˆ
    test_results["Playwright MCPé›†æˆ"] = test_playwright_mcp_integration()
    
    # 5. æµ‹è¯•çœŸå®Playwrightæœç´¢(å¼‚æ­¥)
    try:
        test_results["çœŸå®Playwrightæœç´¢"] = asyncio.run(test_real_playwright_search())
    except Exception as e:
        logger.error(f"çœŸå®Playwrightæœç´¢æµ‹è¯•å¼‚å¸¸: {e}")
        test_results["çœŸå®Playwrightæœç´¢"] = False
    
    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤æˆåŠŸ!")
        logger.info("\nâœ… ç¡®è®¤ä¿®å¤æ•ˆæœ:")
        logger.info("   1. åŸå¸‚ä»£ç æ˜ å°„å·²ç»Ÿä¸€ä¸”æ­£ç¡®")
        logger.info("   2. åœ°ç‚¹ä¿¡æ¯ä¼šä¸é€‰æ‹©çš„åŸå¸‚åŒ¹é…") 
        logger.info("   3. URLæ ¼å¼å·²ä¿®å¤ä¸ºçœŸå®å²—ä½è¯¦æƒ…é¡µ")
        logger.info("   4. å²—ä½æå–é€»è¾‘å·²å¢å¼º")
        
    elif passed >= total * 0.8:
        logger.info("ğŸ”§ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œä¿®å¤åŸºæœ¬æˆåŠŸ")
        logger.info("   å¯èƒ½å­˜åœ¨çš„é—®é¢˜:")
        for test_name, result in test_results.items():
            if not result:
                logger.info(f"   - {test_name}: éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
                
    else:
        logger.warning("âš ï¸ å¤šæ•°æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤")
    
    logger.info(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    logger.info("1. è¿è¡Œ python run_web.py å¯åŠ¨åº”ç”¨")
    logger.info("2. é€‰æ‹©ä¸åŒåŸå¸‚æµ‹è¯•åœ°ç‚¹åŒ¹é…")
    logger.info("3. é€‰æ‹©Playwright MCPå¼•æ“æµ‹è¯•çœŸå®æŠ“å–")
    logger.info("4. æ£€æŸ¥å²—ä½URLæ˜¯å¦æŒ‡å‘å…·ä½“å²—ä½è¯¦æƒ…")


if __name__ == "__main__":
    main()