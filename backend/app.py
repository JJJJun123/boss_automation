#!/usr/bin/env python3
"""
Bossç›´è˜è‡ªåŠ¨åŒ–Webåº”ç”¨åç«¯
Flask + SocketIO å®ç°
"""

import os
import sys
import logging
import threading
from flask import Flask, request, jsonify, session, render_template
from flask_cors import CORS
from flask_socketio import SocketIO, emit
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config_manager import ConfigManager
from crawler.unified_crawler_interface import unified_search_jobs, get_crawler_capabilities
from analyzer.enhanced_job_analyzer import EnhancedJobAnalyzer


# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
app.secret_key = 'boss-zhipin-automation-secret-key-2024'  # æ·»åŠ secret keyç”¨äºsession

# é…ç½®CORS
CORS(app, origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:5000", "http://127.0.0.1:5000"])

# é…ç½®SocketIO
socketio = SocketIO(app, cors_allowed_origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:5000", "http://127.0.0.1:5000"])

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
config_manager = None
current_spider = None
current_job = None  # å­˜å‚¨å½“å‰åˆ†æä»»åŠ¡çŠ¶æ€


def init_config():
    """åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨"""
    global config_manager
    try:
        config_manager = ConfigManager()
        logger.info("é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def emit_progress(message, progress=None, data=None):
    """å‘é€è¿›åº¦æ›´æ–°åˆ°å‰ç«¯"""
    payload = {
        'message': message,
        'timestamp': datetime.now().strftime('%H:%M:%S')
    }
    if progress is not None:
        payload['progress'] = progress
    if data is not None:
        payload['data'] = data
    
    socketio.emit('progress_update', payload)
    logger.info(f"Progress: {message}")


@app.route('/')
def serve_frontend():
    """æä¾›å‰ç«¯é¡µé¢"""
    return render_template('index.html')


@app.route('/api/health')
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })


@app.route('/api/config', methods=['GET'])
def get_config():
    """è·å–å½“å‰é…ç½®"""
    try:
        if not config_manager:
            return jsonify({'error': 'é…ç½®ç®¡ç†å™¨æœªåˆå§‹åŒ–'}), 500
        
        search_config = config_manager.get_search_config()
        ai_config = config_manager.get_ai_config()
        
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        ai_config.pop('api_key', None)
        
        return jsonify({
            'search': search_config,
            'ai': ai_config,
            'app': config_manager.get_app_config()
        })
    except Exception as e:
        logger.error(f"è·å–é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/config', methods=['POST'])
def update_config():
    """æ›´æ–°ç”¨æˆ·é…ç½®"""
    try:
        if not config_manager:
            return jsonify({'error': 'é…ç½®ç®¡ç†å™¨æœªåˆå§‹åŒ–'}), 500
        
        data = request.get_json()
        
        # æ›´æ–°æœç´¢é…ç½®
        if 'search' in data:
            for key, value in data['search'].items():
                config_manager.set_user_preference(f'search.{key}', value)
        
        # æ›´æ–°AIé…ç½®
        if 'ai_analysis' in data:
            for key, value in data['ai_analysis'].items():
                config_manager.set_user_preference(f'ai_analysis.{key}', value)
        
        # ä¿å­˜é…ç½®
        config_manager.save_user_preferences()
        
        return jsonify({'message': 'é…ç½®æ›´æ–°æˆåŠŸ'})
    except Exception as e:
        logger.error(f"æ›´æ–°é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_resume', methods=['POST'])
def upload_resume():
    """å¤„ç†ç®€å†ä¸Šä¼ å’Œåˆ†æ"""
    try:
        if 'resume' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'})
        
        file = request.files['resume']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æœªé€‰æ‹©æ–‡ä»¶'})
        
        logger.info(f"æ¥æ”¶åˆ°æ–‡ä»¶: {file.filename}, ç±»å‹: {file.content_type}")
        
        # ä½¿ç”¨æ–°çš„è§£æå™¨
        from analyzer.resume.resume_parser_v2 import ResumeParserV2
        from analyzer.resume.resume_analyzer import ResumeAnalyzer
        
        parser = ResumeParserV2()
        
        # è§£æç®€å†æ–‡æœ¬ï¼ˆç›´æ¥ä»å†…å­˜è§£æï¼Œä¸ä¿å­˜æ–‡ä»¶ï¼‰
        resume_text = parser.parse_uploaded_file(file)
        
        if "æ–‡ä»¶è§£æå¤±è´¥" in resume_text:
            logger.error(f"æ–‡ä»¶è§£æé”™è¯¯: {resume_text}")
            return jsonify({
                'success': False, 
                'error': resume_text
            })
        
        logger.info(f"ç®€å†è§£ææˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(resume_text)} å­—ç¬¦")
        
        # è°ƒè¯•ï¼šä¿å­˜ç®€å†æ–‡æœ¬ç”¨äºè°ƒè¯•
        try:
            with open("debug_resume_text.txt", "w", encoding='utf-8') as f:
                f.write("=== ä¸Šä¼ çš„ç®€å†æ–‡æœ¬ ===\n")
                f.write(f"æ–‡ä»¶å: {file.filename}\n")
                f.write(f"é•¿åº¦: {len(resume_text)}\n")
                f.write(f"å‰100å­—ç¬¦: {repr(resume_text[:100])}\n")
                f.write("\n=== å®Œæ•´æ–‡æœ¬ ===\n")
                f.write(resume_text)
            print(f"ç®€å†æ–‡æœ¬å·²ä¿å­˜åˆ° debug_resume_text.txt")
        except Exception as debug_e:
            print(f"ä¿å­˜ç®€å†æ–‡æœ¬å¤±è´¥: {debug_e}")
        
        # AIåˆ†æç®€å† - ä½¿ç”¨ç»Ÿä¸€çš„AIæ¶æ„ï¼Œä»é…ç½®è¯»å–AIæä¾›å•†
        try:
            from config.config_manager import ConfigManager
            config_manager = ConfigManager()
            ai_provider = config_manager.get_app_config('ai.default_provider', 'claude')
        except Exception:
            ai_provider = 'claude'
        
        analyzer = ResumeAnalyzer(ai_provider=ai_provider)
        ai_analysis = analyzer.analyze_resume(resume_text)
        
        # ä¿å­˜å®Œæ•´çš„ç®€å†åˆ†æç»“æœåˆ°æ–‡ä»¶
        from analyzer.resume.resume_manager import ResumeManager
        resume_manager = ResumeManager()
        
        # æ„å»ºå®Œæ•´çš„ç®€å†æ•°æ® - é€‚é…æ–°çš„LangGPTæ ¼å¼
        resume_core = ai_analysis.get('resume_core', {})
        
        # ä»ç»“æ„åŒ–æ•°æ®ä¸­æå–åŸºæœ¬ä¿¡æ¯
        education = resume_core.get('education', [])
        work_experience = resume_core.get('work_experience', [])
        skills = resume_core.get('skills', {})
        
        # ä¼°ç®—å·¥ä½œå¹´é™
        experience_years = len(work_experience) * 2 if work_experience else 0  # ç®€å•ä¼°ç®—
        
        # è·å–æœ€é«˜å­¦å†
        highest_degree = 'æœªæä¾›'
        if education and len(education) > 0:
            highest_degree = education[0].get('degree', 'æœªæä¾›')
        
        resume_full_data = {
            'basic_info': {
                'name': 'å·²è§£æ',  # æ–°æ ¼å¼ä¸å†åŒ…å«ä¸ªäººä¿¡æ¯
                'current_position': work_experience[0].get('position', 'æœªæä¾›') if work_experience else 'æœªæä¾›',
                'phone': 'å·²è„±æ•',  # éšç§ä¿æŠ¤
                'email': 'å·²è„±æ•'   # éšç§ä¿æŠ¤
            },
            'skills': skills.get('hard_skills', []) + skills.get('soft_skills', []),
            'experience_years': experience_years,
            'education_info': {'highest_degree': highest_degree},
            'work_experience': work_experience,
            'strengths': ai_analysis.get('strengths', []),
            'weaknesses': ai_analysis.get('weaknesses', []),  # æ–°å¢åŠ£åŠ¿å­—æ®µ
            'job_intentions': ai_analysis.get('recommended_positions', []),  # ä½¿ç”¨æ–°å­—æ®µå
            'salary_expectations': {'min': 15, 'max': 35},  # é»˜è®¤å€¼
            'resume_core': resume_core,  # ä¿å­˜å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®
            'resume_text': resume_text,  # ä¿å­˜åŸå§‹ç®€å†æ–‡æœ¬
            'filename': file.filename,
            'upload_time': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        resume_manager.save_resume(resume_full_data)
        logger.info("ç®€å†ä¿¡æ¯å·²ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ")
        
        # æ„å»ºç”¨äºæ˜¾ç¤ºçš„ç®€åŒ–æ•°æ®
        resume_data = {
            'name': resume_full_data['basic_info']['name'],
            'current_position': resume_full_data['basic_info']['current_position'],
            'experience_years': f"{resume_full_data['experience_years']}å¹´",
            'phone': 'å·²è„±æ•',
            'email': 'å·²è„±æ•',
            'technical_skills': resume_full_data['skills'][:5] if resume_full_data['skills'] else [],  # åªæ˜¾ç¤ºå‰5ä¸ªæŠ€èƒ½
            'education': ai_analysis.get('education_info', {}).get('highest_degree', 'æœªæä¾›'),
            'filename': file.filename,
            'upload_time': datetime.now().isoformat()
        }
        
        # å­˜å‚¨åˆ°sessionï¼ˆåªå­˜å‚¨æ‘˜è¦ä¿¡æ¯ï¼‰
        session['resume_data'] = resume_data
        session['resume_summary'] = {
            'length': len(resume_text),
            'has_text': True,
            'analyzed': True,
            'saved_to_file': True  # æ ‡è®°å·²ä¿å­˜åˆ°æ–‡ä»¶
        }
        session['ai_analysis_summary'] = {
            'strengths_count': len(ai_analysis.get('strengths', [])),
            'weaknesses_count': len(ai_analysis.get('weaknesses', [])),
            'recommended_positions': ai_analysis.get('recommended_positions', []),
            'analyzed_at': datetime.now().isoformat()
        }
        
        # ç®€å†ä¸Šä¼ æ—¶ä¸éœ€è¦åˆ›å»ºå²—ä½åˆ†æå™¨ï¼Œåªåœ¨å²—ä½æœç´¢æ—¶æ‰åˆ›å»º
        # è¿™é‡Œåªä¿å­˜ç®€å†åˆ†æç»“æœï¼Œä¾›åç»­å²—ä½åˆ†æä½¿ç”¨
        global job_analyzer_instance
        if 'job_analyzer_instance' in globals():
            # å¦‚æœå·²æœ‰åˆ†æå™¨å®ä¾‹ï¼Œæ›´æ–°ç®€å†åˆ†ææ•°æ®
            if hasattr(job_analyzer_instance, 'set_resume_analysis'):
                job_analyzer_instance.set_resume_analysis(ai_analysis)
            else:
                job_analyzer_instance.resume_analysis = ai_analysis
            print("ğŸ¯ ç®€å†åˆ†æç»“æœå·²åŠ è½½åˆ°ç°æœ‰å²—ä½åˆ†æå™¨")
        
        strengths_count = len(ai_analysis.get('strengths', []))
        weaknesses_count = len(ai_analysis.get('weaknesses', []))
        logger.info(f"ç®€å†åˆ†æå®Œæˆ: {resume_data['name']}, ä¼˜åŠ¿: {strengths_count}é¡¹, æ”¹è¿›ç‚¹: {weaknesses_count}é¡¹")
        
        return jsonify({
            'success': True,
            'resume_data': resume_data,
            'ai_analysis': ai_analysis
        })
        
    except Exception as e:
        logger.error(f"ç®€å†ä¸Šä¼ å¤„ç†å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False, 
            'error': f"å¤„ç†å¤±è´¥: {str(e)}"
        })

@app.route('/api/delete_resume', methods=['POST'])
def delete_resume():
    try:
        # æ¸…é™¤sessionä¸­çš„ç®€å†æ•°æ®
        session.pop('resume_data', None)
        session.pop('ai_analysis', None)
        
        # æ¸…é™¤JobAnalyzerä¸­çš„ç®€å†åˆ†æ
        global job_analyzer_instance
        if 'job_analyzer_instance' in globals():
            job_analyzer_instance.resume_analysis = None
        
        # æ¸…é™¤æŒä¹…åŒ–çš„ç®€å†æ–‡ä»¶
        from analyzer.resume.resume_manager import ResumeManager
        resume_manager = ResumeManager()
        resume_manager.clear_resume()
        
        return jsonify({'success': True})
        
    except Exception as e:
        print(f"åˆ é™¤ç®€å†å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/resume/info', methods=['GET'])
def get_resume_info():
    """è·å–å½“å‰ä¿å­˜çš„ç®€å†ä¿¡æ¯"""
    try:
        from analyzer.resume.resume_manager import ResumeManager
        resume_manager = ResumeManager()
        
        if resume_manager.has_resume():
            profile = resume_manager.get_personal_profile()
            return jsonify({
                'success': True,
                'has_resume': True,
                'resume_info': {
                    'name': profile.get('name', 'æœªçŸ¥'),
                    'skills': profile.get('skills', []),
                    'experience_years': profile.get('experience_years', 0),
                    'strengths': profile.get('strengths', []),
                    'weaknesses': profile.get('weaknesses', []),
                    'job_intentions': profile.get('job_intentions', [])
                }
            })
        else:
            return jsonify({
                'success': True,
                'has_resume': False,
                'message': 'è¯·å…ˆä¸Šä¼ ç®€å†'
            })
            
    except Exception as e:
        logger.error(f"è·å–ç®€å†ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/resume/update_intentions', methods=['POST'])
def update_job_intentions():
    """æ›´æ–°æ±‚èŒæ„å‘"""
    try:
        data = request.json
        intentions = data.get('intentions', [])
        
        from analyzer.resume.resume_manager import ResumeManager
        resume_manager = ResumeManager()
        
        if not resume_manager.has_resume():
            return jsonify({
                'success': False,
                'error': 'è¯·å…ˆä¸Šä¼ ç®€å†'
            })
        
        success = resume_manager.update_job_intentions(intentions)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'æ±‚èŒæ„å‘å·²æ›´æ–°'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ›´æ–°å¤±è´¥'
            })
            
    except Exception as e:
        logger.error(f"æ›´æ–°æ±‚èŒæ„å‘å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/jobs/search', methods=['POST'])
def start_job_search():
    """å¼€å§‹å²—ä½æœç´¢å’Œåˆ†æ"""
    global current_job, current_spider
    
    try:
        if current_job and current_job.get('status') == 'running':
            return jsonify({'error': 'å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­'}), 400
        
        # è·å–è¯·æ±‚å‚æ•°
        data = request.get_json() or {}
        
        # å¯åŠ¨åå°ä»»åŠ¡
        current_job = {'status': 'starting', 'start_time': datetime.now()}
        
        # ä¼ é€’sessionæ•°æ®ç»™åå°ä»»åŠ¡ï¼ˆé¿å…åœ¨çº¿ç¨‹ä¸­ä½¿ç”¨sessionï¼‰
        session_data = {
            'has_resume_data': 'resume_data' in session,
            'resume_data': session.get('resume_data', None)
        }
        
        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œæœç´¢ä»»åŠ¡
        thread = threading.Thread(target=run_job_search_task, args=(data, session_data))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'message': 'ä»»åŠ¡å·²å¯åŠ¨',
            'task_id': current_job.get('task_id', 'default')
        })
        
    except Exception as e:
        logger.error(f"å¯åŠ¨æœç´¢ä»»åŠ¡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


def run_job_search_task(params, session_data):
    """åœ¨åå°è¿è¡Œå²—ä½æœç´¢ä»»åŠ¡"""
    global current_job, current_spider
    
    try:
        current_job['status'] = 'running'
        emit_progress("ğŸš€ å¼€å§‹åˆå§‹åŒ–çˆ¬è™«...", 5)
        
        # 1. ä»å‰ç«¯å‚æ•°è·å–æœç´¢é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        search_config = config_manager.get_search_config()
        ai_config = config_manager.get_ai_config()
        
        # ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„å‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        keyword = params.get('keyword', search_config['keyword'])
        max_jobs = params.get('max_jobs', search_config['max_jobs'])
        selected_city = params.get('city', 'shanghai')  # é»˜è®¤ä¸Šæµ·
        # ai_modelå‚æ•°å·²ç§»é™¤ï¼Œç³»ç»Ÿå›ºå®šä½¿ç”¨EnhancedJobAnalyzerï¼ˆGLM+DeepSeekï¼‰
        
        # è·å–åŸå¸‚ä»£ç 
        city_codes = search_config['city_codes']
        city_code = city_codes.get(selected_city, {}).get('code', '101210100')
        city_name = city_codes.get(selected_city, {}).get('name', 'ä¸Šæµ·')
        
        emit_progress(f"ğŸ” æœç´¢è®¾ç½®: {keyword} | {city_name} | {max_jobs}ä¸ªå²—ä½", 10)
        
        # 2. ä½¿ç”¨ç»Ÿä¸€çˆ¬è™«å¼•æ“æœç´¢å²—ä½
        emit_progress("ğŸ•·ï¸ å¯åŠ¨ç»Ÿä¸€çˆ¬è™«å¼•æ“...", 20)
        
        # åŸå¸‚ä»£ç æ˜ å°„åˆ°åŸå¸‚åç§°
        city_map = {
            "101280600": "shenzhen",    # æ·±åœ³
            "101020100": "shanghai",    # ä¸Šæµ·
            "101010100": "beijing",     # åŒ—äº¬
            "101210100": "hangzhou"     # æ­å·
        }
        city_name = city_map.get(city_code, "shanghai")
        
        # ä½¿ç”¨ç»Ÿä¸€çˆ¬è™«æ¥å£è¿›è¡Œæœç´¢
        import asyncio
        jobs = asyncio.run(unified_search_jobs(keyword, city_name, max_jobs))
        
        emit_progress(f"ğŸ” æœç´¢å®Œæˆ: æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½", 50)
        
        if not jobs:
            raise Exception("æœªæ‰¾åˆ°ä»»ä½•å²—ä½")
        
        emit_progress(f"ğŸ“Š æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½ï¼Œå¼€å§‹AIåˆ†æ...", 50)
        
        # 5. æ£€æŸ¥æ˜¯å¦æœ‰ç®€å†ï¼Œæ— ç®€å†æ—¶ä¸è¿›è¡ŒAIåˆ†æ
        from analyzer.resume.resume_manager import ResumeManager
        resume_manager = ResumeManager()
        
        # åŒé‡æ£€æŸ¥ï¼šæ—¢è¦æ–‡ä»¶å­˜åœ¨ï¼Œä¹Ÿè¦sessionä¸­æœ‰ç®€å†è®°å½•
        has_file_resume = resume_manager.has_resume()
        has_session_resume = session_data.get('has_resume_data', False)
        
        if not has_file_resume or not has_session_resume:
            # æ— ç®€å†æ—¶ç›´æ¥è¿”å›åŸå§‹å²—ä½æ•°æ®ï¼Œä¸è¿›è¡ŒAIåˆ†æ
            if not has_file_resume:
                emit_progress("âš ï¸ æœªæ£€æµ‹åˆ°ç®€å†æ–‡ä»¶ï¼Œè·³è¿‡AIåˆ†æ", 80)
            else:
                emit_progress("âš ï¸ å½“å‰ä¼šè¯æ— ç®€å†è®°å½•ï¼Œè·³è¿‡AIåˆ†æ", 80)
            
            # ä¸ºæ‰€æœ‰å²—ä½æ ‡è®°ä¸º"éœ€è¦ç®€å†"
            jobs_without_analysis = []
            for job in jobs:
                job['analysis'] = {
                    'score': -1,
                    'overall_score': -1,
                    'recommendation': 'éœ€è¦ç®€å†',
                    'reason': 'è¯·å…ˆä¸Šä¼ ç®€å†åå†è¿›è¡Œå²—ä½åŒ¹é…åˆ†æ',
                    'summary': 'ä¸Šä¼ ç®€å†åå¯è·å¾—è¯¦ç»†çš„åŒ¹é…åº¦åˆ†æ',
                    'requires_resume': True
                }
                jobs_without_analysis.append(job)
            
            # 7. ä¿å­˜ç»“æœï¼ˆæ— åˆ†æç‰ˆæœ¬ï¼‰
            emit_progress("ğŸ’¾ ä¿å­˜æœç´¢ç»“æœ...", 95)
            from utils.data_saver import save_all_job_results
            save_all_job_results(jobs_without_analysis, [])  # ä¿å­˜åŸå§‹å²—ä½ï¼Œåˆæ ¼å²—ä½ä¸ºç©º
            
            # 9. å®Œæˆï¼ˆæ— åˆ†æç‰ˆæœ¬ï¼‰
            current_job.update({
                'status': 'completed',
                'end_time': datetime.now(),
                'results': [],  # æ— åˆæ ¼å²—ä½
                'analyzed_jobs': jobs_without_analysis,
                'total_jobs': len(jobs),
                'analyzed_jobs_count': 0,  # æœªè¿›è¡Œåˆ†æ
                'qualified_jobs': 0,
                'market_analysis': None,
                'requires_resume': True  # æ ‡è®°éœ€è¦ç®€å†
            })
            
            emit_progress(f"ğŸ“‹ æœç´¢å®Œæˆ! æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½ï¼Œè¯·ä¸Šä¼ ç®€å†åè¿›è¡ŒAIåˆ†æ", 100, {
                'results': [],
                'all_jobs': jobs_without_analysis,
                'market_analysis': None,
                'requires_resume': True,
                'stats': {
                    'total': len(jobs),
                    'analyzed': 0,
                    'qualified': 0
                }
            })
            
            # å‘é€æœç´¢å®Œæˆäº‹ä»¶ï¼Œé‡ç½®å‰ç«¯æŒ‰é’®çŠ¶æ€
            socketio.emit('search_complete', {'status': 'success', 'message': 'æœç´¢å®Œæˆï¼Œè¯·ä¸Šä¼ ç®€å†è¿›è¡Œåˆ†æ'})
            return
        
        # æœ‰ç®€å†æ—¶ç»§ç»­AIåˆ†ææµç¨‹
        emit_progress("ğŸ“ æ£€æµ‹åˆ°ç®€å†ï¼Œå¼€å§‹AIæ™ºèƒ½åˆ†æ...", 50)
        
        # 6. AIåˆ†æ - æ”¯æŒåŠ¨æ€æ¨¡å‹é€‰æ‹©
        global job_analyzer_instance
        
        # å¦‚æœæ²¡æœ‰ç°æœ‰å®ä¾‹ï¼Œåˆ›å»ºæ–°çš„åˆ†æå™¨
        if 'job_analyzer_instance' not in globals():
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆ†å±‚åˆ†æå™¨
            use_smart_analyzer = ai_config.get('use_smart_analyzer', False)  # é»˜è®¤å…³é—­ï¼Œéœ€è¦æ‰‹åŠ¨å¯ç”¨
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ··åˆAIæ¨¡å¼ï¼ˆGLM+DeepSeekï¼‰- å¼ºåˆ¶ä½¿ç”¨ä»¥è·å¾—å¸‚åœºåˆ†ææŠ¥å‘Š
            use_enhanced_analyzer = True  # å¼ºåˆ¶å¯ç”¨EnhancedJobAnalyzerä»¥è·å¾—å®Œæ•´çš„å¸‚åœºåˆ†æ
            
            # ä»ResumeManagerè·å–æœ€æ–°çš„ç®€å†åˆ†ææ•°æ®
            current_resume_analysis = None
            try:
                from analyzer.resume.resume_manager import ResumeManager
                resume_manager = ResumeManager()
                current_resume_data = resume_manager.get_current_resume()
                if current_resume_data:
                    current_resume_analysis = current_resume_data
                    print(f"ğŸ“‹ ä»ResumeManagerè·å–åˆ°ç®€å†æ•°æ®: {current_resume_data.get('basic_info', {}).get('name', 'æœªçŸ¥')}")
            except Exception as e:
                print(f"âš ï¸ è·å–ç®€å†æ•°æ®å¤±è´¥: {e}")
                # å°è¯•ä»ç°æœ‰å®ä¾‹è·å–ï¼ˆfallbackï¼‰
                if 'job_analyzer_instance' in globals() and hasattr(job_analyzer_instance, 'resume_analysis'):
                    current_resume_analysis = job_analyzer_instance.resume_analysis
            
            if use_smart_analyzer:
                print(f"ğŸ’ åˆ›å»ºæ™ºèƒ½åˆ†å±‚JobAnalyzerå®ä¾‹ï¼ˆGLMæ‰¹é‡æå–+DeepSeekæ‰¹é‡è¯„åˆ†+Claudeæ·±åº¦åˆ†æï¼‰")
                print(f"ğŸ’° é¢„æœŸæˆæœ¬: $0.65/100ä¸ªå²—ä½")
                
                # åˆ›å»ºæ™ºèƒ½åˆ†æå™¨å®ä¾‹ - å®é™…ä¸ä¼šæ‰§è¡Œï¼Œå› ä¸ºuse_smart_analyzeræ€»æ˜¯False
                # job_analyzer_instance = SmartJobAnalyzer()  # å·²å¼ƒç”¨
                pass
                
                # æ¢å¤ç®€å†åˆ†ææ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                if current_resume_analysis:
                    job_analyzer_instance.resume_analysis = current_resume_analysis
                    print("ğŸ¯ å·²æ¢å¤ç®€å†æ•°æ®åˆ°æ™ºèƒ½åˆ†æå™¨å®ä¾‹")
                    
            elif use_enhanced_analyzer:
                print(f"ğŸš€ åˆ›å»ºå¢å¼ºå‹JobAnalyzerå®ä¾‹ï¼ˆGLM+Claudeæ··åˆæ¨¡å¼ï¼‰")
                
                # åˆ›å»ºå¢å¼ºåˆ†æå™¨å®ä¾‹
                job_analyzer_instance = EnhancedJobAnalyzer(
                    extraction_provider="glm",  # GLM-4.5ç”¨äºä¿¡æ¯æå–
                    analysis_provider="claude"  # Claudeç”¨äºåˆ†æ
                )
                
                # æ¢å¤ç®€å†åˆ†ææ•°æ®
                if current_resume_analysis:
                    job_analyzer_instance.resume_analysis = current_resume_analysis
                    print("ğŸ¯ å·²æ¢å¤ç®€å†æ•°æ®åˆ°å¢å¼ºåˆ†æå™¨å®ä¾‹")
            else:
                print(f"ğŸ”„ åˆ›å»ºä¼ ç»ŸJobAnalyzerå®ä¾‹ï¼Œæ¨¡å‹: {ai_config['provider']}")
                
                # åˆ›å»ºä¼ ç»Ÿåˆ†æå™¨å®ä¾‹
                job_analyzer_instance = JobAnalyzer(ai_provider=ai_config['provider'])
                
                # æ¢å¤ç®€å†åˆ†ææ•°æ®
                if current_resume_analysis:
                    job_analyzer_instance.resume_analysis = current_resume_analysis
                    print("ğŸ¯ å·²æ¢å¤ç®€å†æ•°æ®åˆ°ä¼ ç»Ÿåˆ†æå™¨å®ä¾‹")
        else:
            # ä½¿ç”¨ç°æœ‰å®ä¾‹ï¼Œä½†æ›´æ–°æœ€æ–°çš„ç®€å†æ•°æ®
            if current_resume_analysis:
                job_analyzer_instance.resume_analysis = current_resume_analysis
                print("ğŸ¯ æ›´æ–°ç°æœ‰åˆ†æå™¨çš„ç®€å†æ•°æ®")
            elif hasattr(job_analyzer_instance, 'resume_analysis') and job_analyzer_instance.resume_analysis:
                print("ğŸ¯ ä½¿ç”¨ç°æœ‰åˆ†æå™¨ä¸­çš„ç®€å†æ•°æ®")
            else:
                print("âš ï¸ ç°æœ‰åˆ†æå™¨ä¸­æ²¡æœ‰ç®€å†æ•°æ®")
        
        analyzer = job_analyzer_instance
        
        # ä¸ºæ‰€æœ‰å²—ä½åˆå§‹åŒ–åˆ†æç»“æœ
        all_jobs_with_analysis = []
        
        # ä½¿ç”¨æ–°çš„æ‰¹é‡åˆ†ææ–¹æ³•ï¼ˆåŒ…å«AIå²—ä½è¦æ±‚æ€»ç»“å’Œæˆæœ¬ä¼˜åŒ–ï¼‰
        emit_progress("ğŸ§  å¯åŠ¨AIå²—ä½è¦æ±‚æ€»ç»“å’Œæ™ºèƒ½åˆ†æ...", 50)
        
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ™ºèƒ½åˆ†å±‚åˆ†æå™¨
            # ä½¿ç”¨å¢å¼ºåˆ†æå™¨çš„åˆ†ææ–¹æ³•ï¼ˆåŒ…å«å²—ä½è¦æ±‚æ€»ç»“ï¼‰
            all_jobs_with_analysis = analyzer.analyze_jobs(jobs)
            
            # å¸‚åœºåˆ†æå·²å®Œæˆ
            emit_progress(f"ğŸ“Š å¸‚åœºåˆ†æå®Œæˆ", 80)
            
        except Exception as e:
            logger.error(f"æ–°åˆ†ææ–¹æ³•å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»Ÿåˆ†æ: {e}")
            # é‡æ–°åˆå§‹åŒ–ï¼Œé¿å…é‡å¤æ•°æ®
            all_jobs_with_analysis = []
            # é™çº§åˆ°ä¼ ç»Ÿåˆ†ææ–¹æ³•
            for i, job in enumerate(jobs):
                progress = 50 + (i / len(jobs)) * 30
                emit_progress(f"ğŸ¤– åˆ†æç¬¬ {i+1}/{len(jobs)} ä¸ªå²—ä½...", progress)
                
                try:
                    analysis_result = analyzer.ai_client.analyze_job_match(
                        job, analyzer.user_requirements
                    )
                    job['analysis'] = analysis_result
                except Exception as e:
                    logger.error(f"åˆ†æå²—ä½å¤±è´¥: {e}")
                    job['analysis'] = {
                        "score": 0,
                        "recommendation": "åˆ†æå¤±è´¥",
                        "reason": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}",
                        "summary": "æ— æ³•åˆ†ææ­¤å²—ä½"
                    }
                
                all_jobs_with_analysis.append(job)
        
        # 7. è¿‡æ»¤å’Œæ’åº
        emit_progress("ğŸ¯ è¿‡æ»¤å’Œæ’åºç»“æœ...", 85)
        # ç­›é€‰åˆæ ¼å²—ä½
        filtered_jobs = analyzer.filter_and_sort_jobs(all_jobs_with_analysis, ai_config['min_score'])
        
        # 8. ä¿å­˜ç»“æœ
        emit_progress("ğŸ’¾ ä¿å­˜ç»“æœ...", 95)
        # ä½¿ç”¨æ–°çš„ä¿å­˜å‡½æ•°ï¼Œä¿å­˜æ‰€æœ‰å²—ä½
        from utils.data_saver import save_all_job_results
        save_all_job_results(all_jobs_with_analysis, filtered_jobs)  # ä¿å­˜æ‰€æœ‰å²—ä½
        
        # 9. è·å–å¸‚åœºåˆ†æç»“æœ
        # EnhancedJobAnalyzeræœ‰å®Œæ•´çš„å¸‚åœºåˆ†æ
        market_analysis = analyzer.get_market_analysis()
        logger.info(f"EnhancedJobAnalyzerå¸‚åœºåˆ†æè·å–: {market_analysis is not None}")
        if market_analysis:
            logger.info(f"å¸‚åœºåˆ†æåŒ…å«æŠ€èƒ½è¦æ±‚: {'skill_requirements' in market_analysis}")
            logger.info(f"å¸‚åœºåˆ†æåŒ…å«æ ¸å¿ƒèŒè´£: {'core_responsibilities' in market_analysis}")
        
        # 10. å®Œæˆ
        current_job.update({
            'status': 'completed',
            'end_time': datetime.now(),
            'results': filtered_jobs,
            'analyzed_jobs': all_jobs_with_analysis,  # å­˜å‚¨æ‰€æœ‰å²—ä½
            'total_jobs': len(jobs),
            'analyzed_jobs_count': len(all_jobs_with_analysis),
            'qualified_jobs': len(filtered_jobs),
            'market_analysis': market_analysis  # ä¿å­˜å¸‚åœºåˆ†æ
        })
        
        emit_progress(f"âœ… ä»»åŠ¡å®Œæˆ! æ‰¾åˆ° {len(filtered_jobs)} ä¸ªåˆé€‚å²—ä½", 100, {
            'results': filtered_jobs,
            'all_jobs': all_jobs_with_analysis,  # è¿”å›æ‰€æœ‰å²—ä½
            'market_analysis': market_analysis,  # ä¼ é€’å¸‚åœºåˆ†æ
            'stats': {
                'total': len(jobs),  # ä½¿ç”¨åŸå§‹æŠ“å–çš„å²—ä½æ•°é‡
                'analyzed': len(all_jobs_with_analysis),  # åˆ†æçš„å²—ä½æ•°é‡
                'qualified': len(filtered_jobs)  # åˆæ ¼çš„å²—ä½æ•°é‡
            }
        })
        
        # å‘é€æœç´¢å®Œæˆäº‹ä»¶ï¼Œé‡ç½®å‰ç«¯æŒ‰é’®çŠ¶æ€
        socketio.emit('search_complete', {'status': 'success', 'message': 'æœç´¢å®Œæˆ'})
        
    except Exception as e:
        logger.error(f"æœç´¢ä»»åŠ¡å¤±è´¥: {e}")
        # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        current_job.update({
            'status': 'failed',
            'error': str(e),
            'end_time': datetime.now()
        })
        emit_progress(f"âŒ ä»»åŠ¡å¤±è´¥: {str(e)}", None)
        
        # å‘é€æœç´¢å®Œæˆäº‹ä»¶ï¼Œé‡ç½®å‰ç«¯æŒ‰é’®çŠ¶æ€
        socketio.emit('search_complete', {'status': 'failed', 'message': f'æœç´¢å¤±è´¥: {str(e)}'})
        
    finally:
        # æ¸…ç†èµ„æº
        if current_spider:
            try:
                current_spider.close()
            except:
                pass
            current_spider = None


@app.route('/api/jobs/all')
def get_all_jobs():
    """è·å–æ‰€æœ‰æœç´¢åˆ°çš„å²—ä½ï¼ˆæœªè¿‡æ»¤ï¼‰"""
    try:
        from utils.data_saver import load_all_job_results
        
        # å°è¯•ä»ä¿å­˜çš„æ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰å²—ä½
        job_data = load_all_job_results()
        if job_data and 'all_jobs' in job_data:
            all_jobs = job_data['all_jobs']
            logger.info(f"âœ… ä»æ–‡ä»¶åŠ è½½äº† {len(all_jobs)} ä¸ªå²—ä½")
            return jsonify({
                'jobs': all_jobs,
                'total': len(all_jobs),
                'metadata': job_data.get('metadata', {})
            })
        
        # å¦‚æœæ–‡ä»¶ä¸­æ²¡æœ‰æ•°æ®ï¼Œfallbackåˆ°current_job
        if current_job and 'analyzed_jobs' in current_job:
            jobs = current_job.get('analyzed_jobs', [])
            logger.info(f"âš ï¸ ä»å†…å­˜åŠ è½½äº† {len(jobs)} ä¸ªå²—ä½")
            return jsonify({
                'jobs': jobs,
                'total': len(jobs)
            })
        
        return jsonify({'error': 'æ²¡æœ‰å¯ç”¨çš„æœç´¢ç»“æœï¼Œè¯·å…ˆè¿›è¡Œæœç´¢'}), 404
        
    except Exception as e:
        logger.error(f"è·å–æ‰€æœ‰å²—ä½å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/jobs/results')
def get_job_results():
    """è·å–æœ€æ–°çš„å²—ä½æœç´¢ç»“æœ"""
    try:
        if not current_job:
            return jsonify({'error': 'æ²¡æœ‰å¯ç”¨çš„æœç´¢ç»“æœ'}), 404
        
        return jsonify({
            'status': current_job.get('status'),
            'results': current_job.get('results', []),
            'stats': {
                'total_jobs': current_job.get('total_jobs', 0),
                'analyzed_jobs': current_job.get('analyzed_jobs', 0),
                'qualified_jobs': current_job.get('qualified_jobs', 0)
            },
            'start_time': current_job.get('start_time'),
            'end_time': current_job.get('end_time')
        })
        
    except Exception as e:
        logger.error(f"è·å–ç»“æœå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/jobs/status')
def get_job_status():
    """è·å–å½“å‰ä»»åŠ¡çŠ¶æ€"""
    if not current_job:
        return jsonify({'status': 'idle'})
    
    return jsonify({
        'status': current_job.get('status', 'idle'),
        'start_time': current_job.get('start_time'),
        'error': current_job.get('error')
    })


@socketio.on('connect')
def handle_connect():
    """WebSocketè¿æ¥å¤„ç†"""
    logger.info('å®¢æˆ·ç«¯å·²è¿æ¥')
    emit('connected', {'message': 'è¿æ¥æˆåŠŸ'})


@socketio.on('disconnect')
def handle_disconnect():
    """WebSocketæ–­å¼€è¿æ¥å¤„ç†"""
    logger.info('å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥')


if __name__ == '__main__':
    # åˆå§‹åŒ–é…ç½®
    if not init_config():
        logger.error("é…ç½®åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        sys.exit(1)
    
    # å¯åŠ¨åº”ç”¨
    logger.info("å¯åŠ¨Bossç›´è˜è‡ªåŠ¨åŒ–Webåº”ç”¨...")
    socketio.run(app, 
                host='127.0.0.1', 
                port=5000, 
                debug=True,
                use_reloader=False,
                allow_unsafe_werkzeug=True)  # é¿å…é‡è½½æ—¶çš„é—®é¢˜