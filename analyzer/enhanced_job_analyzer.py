#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå²—ä½åˆ†æå™¨
å®ç°ä¸‰é˜¶æ®µåˆ†ææµç¨‹ï¼š
1. ä¿¡æ¯æå–ï¼ˆGLM-4.5ï¼‰
2. å¸‚åœºè®¤çŸ¥åˆ†æï¼ˆDeepSeekç­‰ï¼‰
3. ä¸ªäººåŒ¹é…åˆ†æï¼ˆDeepSeekç­‰ï¼‰
"""

import os
import json
import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

from .ai_client_factory import AIClientFactory
from .job_analyzer import JobAnalyzer
from .prompts.extraction_prompts import ExtractionPrompts
from .prompts.job_analysis_prompts import JobAnalysisPrompts

logger = logging.getLogger(__name__)


class EnhancedJobAnalyzer:
    """å¢å¼ºç‰ˆå²—ä½åˆ†æå™¨ - æ”¯æŒä¸‰é˜¶æ®µæ··åˆæ¨¡å‹åˆ†æ"""
    
    def __init__(self, extraction_provider: str = "glm", 
                 analysis_provider: Optional[str] = None, 
                 model_name: Optional[str] = None,
                 screening_mode: bool = True):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆåˆ†æå™¨
        
        Args:
            extraction_provider: ä¿¡æ¯æå–é˜¶æ®µçš„AIæä¾›å•†ï¼ˆé»˜è®¤GLMï¼‰
            analysis_provider: åˆ†æé˜¶æ®µçš„AIæä¾›å•†ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            model_name: åˆ†æé˜¶æ®µçš„å…·ä½“æ¨¡å‹åç§°
            screening_mode: æ˜¯å¦å¯ç”¨å¿«é€Ÿç­›é€‰æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼‰
        """
        # åˆ›å»ºAIæœåŠ¡å®ä¾‹
        self.extraction_service = AIClientFactory.create_client(extraction_provider, "glm-4.5")
        self.extraction_provider = extraction_provider  # ä¿å­˜providerä¿¡æ¯ä»¥ä¾¿æ˜¾ç¤º
        self.job_analyzer = JobAnalyzer(ai_provider=analysis_provider, model_name=model_name)
        
        # è·å–ç”¨æˆ·é…ç½®
        self.user_requirements = self._get_user_requirements()
        self.user_intentions = self._get_user_intentions()
        self.resume_analysis = None
        self.market_cognition_report = None
        self.screening_mode = screening_mode
        
        print(f"ğŸš€ å¢å¼ºç‰ˆåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ¯ ç­›é€‰æ¨¡å¼: {'å¯ç”¨' if screening_mode else 'ç¦ç”¨'}")
        print(f"ğŸ“‹ ç­›é€‰å¼•æ“: {self.extraction_provider.upper()}")
        print(f"ğŸ§  åˆ†æå¼•æ“: {self.job_analyzer.ai_provider.upper()}")
        
    def _get_user_requirements(self):
        """è·å–ç”¨æˆ·è¦æ±‚é…ç½®"""
        try:
            from config.config_manager import ConfigManager
            config_manager = ConfigManager()
            profile = config_manager.get_user_preference('personal_profile', {})
            
            job_intentions = profile.get('job_intentions', [])
            skills = profile.get('skills', [])
            salary_range = profile.get('salary_range', {})
            excluded_types = profile.get('excluded_job_types', [])
            experience_years = profile.get('experience_years', 0)
            
            requirements = f"""
æ±‚èŒæ„å‘ï¼š
{chr(10).join(f'- {intention}' for intention in job_intentions)}

èƒŒæ™¯è¦æ±‚ï¼š
- å·¥ä½œç»éªŒ: {experience_years}å¹´
- æŠ€èƒ½ä¸“é•¿: {', '.join(skills)}

è–ªèµ„æœŸæœ›ï¼š
- {salary_range.get('min', 15)}K-{salary_range.get('max', 35)}K/æœˆ

ä¸æ¥å—çš„å²—ä½ç±»å‹ï¼š
{chr(10).join(f'- {excluded}' for excluded in excluded_types)}
"""
            return requirements
            
        except Exception:
            # é»˜è®¤é…ç½®
            return """
æ±‚èŒæ„å‘ï¼š
- å¸‚åœºé£é™©ç®¡ç†ç›¸å…³å²—ä½
- AI/äººå·¥æ™ºèƒ½ç›¸å…³å²—ä½

èƒŒæ™¯è¦æ±‚ï¼š
- æœ‰é‡‘èè¡Œä¸šç»éªŒä¼˜å…ˆ
- ç†Ÿæ‚‰é£é™©ç®¡ç†ã€æ•°æ®åˆ†æ

è–ªèµ„æœŸæœ›ï¼š
- 15K-35K/æœˆ
"""
    
    def _get_user_intentions(self):
        """è·å–ç”¨æˆ·æ±‚èŒæ„å‘ï¼ˆç”¨äºå¿«é€Ÿç­›é€‰ï¼‰"""
        try:
            from config.config_manager import ConfigManager
            config_manager = ConfigManager()
            profile = config_manager.get_user_preference('personal_profile', {})
            
            job_intentions = profile.get('job_intentions', [])
            excluded_types = profile.get('excluded_job_types', [])
            
            intentions = "æ±‚èŒæ„å‘ï¼š\n"
            intentions += "\n".join(f"- {intention}" for intention in job_intentions)
            
            if excluded_types:
                intentions += "\n\nä¸æ¥å—çš„å²—ä½ï¼š\n"
                intentions += "\n".join(f"- {excluded}" for excluded in excluded_types)
            
            return intentions
            
        except Exception:
            return "æ±‚èŒæ„å‘ï¼š\n- å¸‚åœºé£é™©ç®¡ç†ç›¸å…³å²—ä½\n- AI/äººå·¥æ™ºèƒ½ç›¸å…³å²—ä½\n- é‡‘èç§‘æŠ€ç›¸å…³å²—ä½"
    
    def set_resume_analysis(self, resume_analysis: Dict[str, Any]):
        """è®¾ç½®ç®€å†åˆ†æç»“æœ"""
        self.resume_analysis = resume_analysis
        print(f"ğŸ“ ç®€å†åˆ†æç»“æœå·²åŠ è½½")
    
    def analyze_jobs(self, jobs_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆ†æå²—ä½ï¼ˆå…¼å®¹åŸJobAnalyzeræ¥å£ï¼‰
        
        Args:
            jobs_list: å²—ä½åˆ—è¡¨
            
        Returns:
            åˆ†æåçš„å²—ä½åˆ—è¡¨
        """
        import asyncio
        
        # è¿è¡Œä¸‰é˜¶æ®µåˆ†æ
        market_report, analyzed_jobs = asyncio.run(self.analyze_jobs_three_stages(jobs_list))
        
        # å­˜å‚¨å¸‚åœºæŠ¥å‘Šä¾›get_market_analysisä½¿ç”¨
        self.market_report = market_report
        
        return analyzed_jobs
    
    async def analyze_jobs_three_stages(self, jobs_list: List[Dict[str, Any]]) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
        """
        ä¸‰é˜¶æ®µå²—ä½åˆ†æ
        
        Args:
            jobs_list: å²—ä½åˆ—è¡¨
            
        Returns:
            (å¸‚åœºè®¤çŸ¥æŠ¥å‘Š, åˆ†æåçš„å²—ä½åˆ—è¡¨)
        """
        print(f"\nğŸ¯ å¼€å§‹ä¸‰é˜¶æ®µæ™ºèƒ½åˆ†æï¼Œå…±{len(jobs_list)}ä¸ªå²—ä½...")
        
        # å­˜å‚¨å½“å‰å¤„ç†çš„å²—ä½åˆ—è¡¨ï¼Œç”¨äºé»˜è®¤æŠ¥å‘Š
        self._current_job_list = jobs_list
        
        if self.screening_mode:
            # æ–°æµç¨‹ï¼šå¿«é€Ÿç­›é€‰æ¨¡å¼
            # é˜¶æ®µ1ï¼šå¿«é€Ÿç­›é€‰ç›¸å…³å²—ä½
            print(f"\nğŸ” é˜¶æ®µ1/3: å¿«é€Ÿç­›é€‰ç›¸å…³å²—ä½ï¼ˆä½¿ç”¨{self.extraction_provider.upper()}ï¼‰...")
            relevant_jobs = await self._stage1_quick_screening(jobs_list)
            
            if not relevant_jobs:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å²—ä½ï¼Œè¿”å›ç©ºç»“æœ")
                return self._get_default_market_report(), []
            
            print(f"âœ… ç­›é€‰å‡º {len(relevant_jobs)}/{len(jobs_list)} ä¸ªç›¸å…³å²—ä½")
            
            # é˜¶æ®µ2ï¼šä¿¡æ¯æå–ï¼ˆåªå¯¹ç›¸å…³å²—ä½ï¼‰
            print(f"\nğŸ“Š é˜¶æ®µ2/3: æå–ç›¸å…³å²—ä½ä¿¡æ¯ï¼ˆä½¿ç”¨{self.extraction_provider.upper()}ï¼‰...")
            extracted_jobs = await self._stage1_extract_job_info(relevant_jobs)
            
            # é˜¶æ®µ3ï¼šå¸‚åœºè®¤çŸ¥åˆ†æ
            print(f"\nğŸ§  é˜¶æ®µ3/3: å¸‚åœºè®¤çŸ¥åˆ†æï¼ˆä½¿ç”¨{self.job_analyzer.ai_provider.upper()}ï¼‰...")
            market_report = await self._stage2_market_cognition_analysis(extracted_jobs)
            self.market_cognition_report = market_report
            
            # é˜¶æ®µ4ï¼šä¸ªäººåŒ¹é…åˆ†æï¼ˆåªå¯¹ç›¸å…³å²—ä½ï¼‰
            print(f"\nğŸ¯ é˜¶æ®µ4/4: ä¸ªäººåŒ¹é…åˆ†æï¼ˆä½¿ç”¨{self.job_analyzer.ai_provider.upper()}ï¼‰...")
            analyzed_jobs = await self._stage3_personal_match_analysis(relevant_jobs, extracted_jobs)
            
            # æ ‡è®°ä¸ç›¸å…³çš„å²—ä½
            all_analyzed_jobs = self._merge_with_irrelevant_jobs(jobs_list, analyzed_jobs, relevant_jobs)
            
            return market_report, all_analyzed_jobs
        else:
            # åŸæµç¨‹ï¼šå…¨é‡åˆ†æ
            # é˜¶æ®µ1ï¼šä¿¡æ¯æå–
            print(f"\nğŸ“Š é˜¶æ®µ1/3: å²—ä½ä¿¡æ¯æå–ï¼ˆä½¿ç”¨{self.extraction_provider.upper()}ï¼‰...")
            extracted_jobs = await self._stage1_extract_job_info(jobs_list)
            
            # é˜¶æ®µ2ï¼šå¸‚åœºè®¤çŸ¥åˆ†æ
            print(f"\nğŸ§  é˜¶æ®µ2/3: å¸‚åœºè®¤çŸ¥åˆ†æï¼ˆä½¿ç”¨{self.job_analyzer.ai_provider.upper()}ï¼‰...")
            market_report = await self._stage2_market_cognition_analysis(extracted_jobs)
            self.market_cognition_report = market_report
            
            # é˜¶æ®µ3ï¼šä¸ªäººåŒ¹é…åˆ†æ
            print(f"\nğŸ¯ é˜¶æ®µ3/3: ä¸ªäººåŒ¹é…åˆ†æï¼ˆä½¿ç”¨{self.job_analyzer.ai_provider.upper()}ï¼‰...")
            analyzed_jobs = await self._stage3_personal_match_analysis(jobs_list, extracted_jobs)
            
            return market_report, analyzed_jobs
    
    async def _stage1_extract_job_info(self, jobs_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ1ï¼šä¿¡æ¯æå–
        ä½¿ç”¨ä½æˆæœ¬æ¨¡å‹ï¼ˆGLM-4.5ï¼‰æå–å…³é”®ä¿¡æ¯
        """
        extracted_jobs = []
        
        for i, job in enumerate(jobs_list, 1):
            if i % 10 == 0:
                print(f"   æå–è¿›åº¦: {i}/{len(jobs_list)}")
            
            try:
                # è·å–æå–æç¤ºè¯
                prompt = ExtractionPrompts.get_job_info_extraction_prompt(job)
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºå®Œæ•´çš„è¾“å…¥è¾“å‡º
                if i <= 2:
                    print(f"\n{'='*60}")
                    print(f"ğŸ” GLMè°ƒè¯•ä¿¡æ¯ - å²—ä½{i}")
                    print(f"{'='*60}")
                    print(f"ã€è¾“å…¥æç¤ºè¯ã€‘")
                    print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
                    print(f"\nã€å²—ä½æ ‡é¢˜ã€‘{job.get('title', '')}")
                    print(f"ã€å²—ä½æè¿°é•¿åº¦ã€‘{len(job.get('job_description', ''))}å­—ç¬¦")
                
                # è°ƒç”¨GLM-4.5è¿›è¡Œä¿¡æ¯æå–ï¼Œè®¾ç½®è¾ƒå°çš„max_tokensé¿å…æ·±åº¦æ€è€ƒæ¨¡å¼ï¼Œä¾èµ–reasoning_contentæå–
                response = self.extraction_service.call_api_simple(prompt, max_tokens=800)
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºå“åº”
                if i <= 2:
                    print(f"\nã€GLMå“åº”ã€‘")
                    print(f"å“åº”é•¿åº¦: {len(response)}å­—ç¬¦")
                    if len(response) == 0:
                        print("âš ï¸ è­¦å‘Š: GLMè¿”å›äº†ç©ºå“åº”ï¼")
                    else:
                        print(f"å“åº”å†…å®¹: {response[:500]}..." if len(response) > 500 else f"å“åº”å†…å®¹: {response}")
                    print(f"{'='*60}\n")
                
                # æ£€æŸ¥ç©ºå“åº”
                if not response or len(response.strip()) == 0:
                    logger.warning(f"å²—ä½{i}çš„GLMå“åº”ä¸ºç©º")
                    raise Exception("GLMè¿”å›ç©ºå“åº”")
                
                # è§£æJSONå“åº”
                extracted_info = self._parse_extraction_result(response)
                
                # ä¿å­˜åŸå§‹å²—ä½ä¿¡æ¯å’Œæå–ç»“æœ
                job_with_extraction = job.copy()
                job_with_extraction['extracted_info'] = extracted_info
                extracted_jobs.append(job_with_extraction)
                
            except Exception as e:
                logger.error(f"æå–å²—ä½{i}ä¿¡æ¯å¤±è´¥: {e}")
                
                # å¦‚æœæ˜¯GLMç½‘ç»œé”™è¯¯ï¼Œå°è¯•é™çº§åˆ°DeepSeek
                if "GLM APIç½‘ç»œè¯·æ±‚å¤±è´¥" in str(e) or "Read timed out" in str(e):
                    print(f"âš ï¸ GLMç½‘ç»œå¼‚å¸¸ï¼Œå°è¯•é™çº§åˆ°DeepSeekè¿›è¡Œå²—ä½{i}çš„ä¿¡æ¯æå–...")
                    try:
                        # ä½¿ç”¨DeepSeekè¿›è¡Œæå–
                        fallback_response = self.job_analyzer.ai_client.call_api_simple(prompt, max_tokens=3000)
                        extracted_info = self._parse_extraction_result(fallback_response)
                        
                        job_with_extraction = job.copy()
                        job_with_extraction['extracted_info'] = extracted_info
                        extracted_jobs.append(job_with_extraction)
                        print(f"âœ… DeepSeeké™çº§æå–æˆåŠŸ")
                        continue
                        
                    except Exception as fallback_error:
                        logger.error(f"DeepSeeké™çº§æå–ä¹Ÿå¤±è´¥: {fallback_error}")
                
                # ä½¿ç”¨é»˜è®¤æå–ç»“æœ
                job_with_extraction = job.copy()
                job_with_extraction['extracted_info'] = self._get_default_extraction()
                extracted_jobs.append(job_with_extraction)
        
        print(f"âœ… ä¿¡æ¯æå–å®Œæˆï¼ŒæˆåŠŸæå–{len(extracted_jobs)}ä¸ªå²—ä½")
        return extracted_jobs
    
    async def _stage2_market_cognition_analysis(self, extracted_jobs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        é˜¶æ®µ2ï¼šå¸‚åœºè®¤çŸ¥åˆ†æ
        åŸºäºæ‰€æœ‰å²—ä½çš„æå–ä¿¡æ¯ç”Ÿæˆå¸‚åœºæ´å¯Ÿ
        """
        try:
            # æå–æ‰€æœ‰çš„extracted_info
            extracted_data = [job.get('extracted_info', {}) for job in extracted_jobs]
            
            # è·å–å¸‚åœºè®¤çŸ¥åˆ†ææç¤ºè¯
            prompt = JobAnalysisPrompts.get_market_cognition_prompt(extracted_data)
            
            # è°ƒç”¨åˆ†ææ¨¡å‹
            response = self.job_analyzer.ai_client.call_api_simple(prompt)
            
            # è§£æç»“æœ
            market_report = self._parse_market_cognition_result(response)
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºå¸‚åœºåˆ†ææŠ¥å‘Šå†…å®¹
            logger.info(f"å¸‚åœºåˆ†ææŠ¥å‘Šå†…å®¹: {json.dumps(market_report.get('market_overview', {}), ensure_ascii=False)}")
            
            # æ˜¾ç¤ºå…³é”®æ´å¯Ÿ
            if 'key_findings' in market_report:
                print(f"\nğŸ” å…³é”®å‘ç°ï¼š")
                for finding in market_report['key_findings']:
                    print(f"   â€¢ {finding}")
            
            # æ˜¾ç¤ºåˆ†æçš„å²—ä½æ•°é‡
            total_analyzed = market_report.get('market_overview', {}).get('total_jobs_analyzed', 0)
            print(f"ğŸ“Š å¸‚åœºåˆ†æåŸºäº {total_analyzed} ä¸ªå²—ä½")
            
            return market_report
            
        except Exception as e:
            logger.error(f"å¸‚åœºè®¤çŸ¥åˆ†æå¤±è´¥: {e}")
            return self._get_default_market_report()
    
    async def _stage3_personal_match_analysis(self, 
                                            original_jobs: List[Dict[str, Any]], 
                                            extracted_jobs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ3ï¼šä¸ªäººåŒ¹é…åˆ†æ
        åŸºäºç®€å†å¯¹æ¯ä¸ªå²—ä½è¿›è¡ŒåŒ¹é…åº¦åˆ†æ
        """
        analyzed_jobs = []
        
        for i, (job, extracted_job) in enumerate(zip(original_jobs, extracted_jobs), 1):
            if i % 10 == 0:
                print(f"   åˆ†æè¿›åº¦: {i}/{len(original_jobs)}")
            
            try:
                # æ ¹æ®æ˜¯å¦æœ‰ç®€å†é€‰æ‹©åˆ†ææ–¹æ³•
                if self.resume_analysis:
                    # ä½¿ç”¨ç®€å†æ™ºèƒ½åŒ¹é…
                    analysis_result = self.job_analyzer.analyze_job_match(
                        job, self.resume_analysis
                    )
                else:
                    # ä½¿ç”¨ç®€å•åŒ¹é…
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºè¾“å…¥å†…å®¹
                    if i <= 2:  # åªæ˜¾ç¤ºå‰2ä¸ª
                        logger.info(f"å²—ä½{i}è¾“å…¥å†…å®¹é¢„è§ˆ:")
                        logger.info(f"æ ‡é¢˜: {job.get('title', '')}")
                        logger.info(f"æè¿°é•¿åº¦: {len(job.get('job_description', ''))}")
                    
                    analysis_result = self.job_analyzer.analyze_job_match_simple(
                        job, self.user_requirements
                    )
                
                # åˆå¹¶åˆ†æç»“æœ
                job['analysis'] = analysis_result
                job['extracted_info'] = extracted_job.get('extracted_info', {})
                analyzed_jobs.append(job)
                
            except Exception as e:
                logger.error(f"åˆ†æå²—ä½{i}å¤±è´¥: {e}")
                job['analysis'] = self._get_fallback_analysis(str(e))
                job['extracted_info'] = extracted_job.get('extracted_info', {})
                analyzed_jobs.append(job)
        
        print(f"âœ… ä¸ªäººåŒ¹é…åˆ†æå®Œæˆï¼Œå…±åˆ†æ {len(analyzed_jobs)} ä¸ªå²—ä½")
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºå‰3ä¸ªå²—ä½çš„åˆ†æç»“æœæ‘˜è¦
        for i, job in enumerate(analyzed_jobs[:3], 1):
            if 'analysis' in job:
                score = job['analysis'].get('score', 0)
                recommendation = job['analysis'].get('recommendation', 'æœªçŸ¥')
                print(f"   å²—ä½{i}: {job.get('title', 'æœªçŸ¥')} - è¯„åˆ†: {score}/10 - æ¨è: {recommendation}")
        
        return analyzed_jobs
    
    def _parse_extraction_result(self, response_text: str) -> Dict[str, Any]:
        """è§£æä¿¡æ¯æå–ç»“æœ"""
        try:
            # å¤„ç†å¯èƒ½åŒ…å«markdownä»£ç å—çš„å“åº”
            import re
            
            # å…ˆå°è¯•æå–```jsonä»£ç å—ä¸­çš„å†…å®¹
            json_code_block = re.search(r'```json\s*\n?(.*?)\n?```', response_text, re.DOTALL)
            if json_code_block:
                try:
                    result = json.loads(json_code_block.group(1).strip())
                    logger.info(f"æˆåŠŸä»markdownä»£ç å—è§£æJSONï¼ŒåŒ…å«é”®: {list(result.keys())}")
                    return result
                except json.JSONDecodeError as e:
                    logger.warning(f"markdownä»£ç å—ä¸­çš„JSONè§£æå¤±è´¥: {e}")
            
            # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
            try:
                result = json.loads(response_text.strip())
                logger.info(f"æˆåŠŸç›´æ¥è§£æJSONï¼ŒåŒ…å«é”®: {list(result.keys())}")
                return result
            except json.JSONDecodeError:
                pass
            
            # æ–¹æ³•3: æŸ¥æ‰¾ä»¥{å¼€å§‹ï¼Œä»¥}ç»“æŸçš„å®Œæ•´JSON
            json_start = response_text.find('{')
            if json_start != -1:
                # æ‰¾åˆ°åŒ¹é…çš„é—­åˆæ‹¬å·
                brace_count = 0
                json_end = json_start
                for i in range(json_start, len(response_text)):
                    if response_text[i] == '{':
                        brace_count += 1
                    elif response_text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
                
                if json_end > json_start:
                    json_str = response_text[json_start:json_end]
                    try:
                        result = json.loads(json_str)
                        logger.info(f"æˆåŠŸé€šè¿‡æ‹¬å·åŒ¹é…è§£æJSONï¼ŒåŒ…å«é”®: {list(result.keys())}")
                        return result
                    except json.JSONDecodeError as e:
                        logger.warning(f"æ‹¬å·åŒ¹é…çš„JSONè§£æå¤±è´¥: {e}")
                        logger.debug(f"å°è¯•è§£æçš„JSON: {json_str[:200]}...")
            
            # æ–¹æ³•4: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼ˆä½œä¸ºåå¤‡ï¼‰
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response_text, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                    logger.info(f"æˆåŠŸé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼è§£æJSON")
                    return result
                except json.JSONDecodeError:
                    pass
            
            logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSONï¼Œå“åº”å¼€å¤´: {response_text[:100]}...")
            return self._get_default_extraction()
            
        except Exception as e:
            logger.error(f"è§£ææå–ç»“æœå¤±è´¥: {e}")
            logger.debug(f"åŸå§‹å“åº”: {response_text[:200]}...")
            return self._get_default_extraction()
    
    def _parse_market_cognition_result(self, response_text: str) -> Dict[str, Any]:
        """è§£æå¸‚åœºè®¤çŸ¥åˆ†æç»“æœ"""
        try:
            import re
            logger = logging.getLogger(__name__)
            
            # 1. å°è¯•ä»markdownä»£ç å—ä¸­æå–JSON
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                # æ¸…ç†JSONä¸­çš„æ³¨é‡Š
                json_str = re.sub(r'//.*?\n', '\n', json_str)  # åˆ é™¤å•è¡Œæ³¨é‡Š
                return json.loads(json_str)
            
            # 2. ç›´æ¥æŸ¥æ‰¾JSONå¯¹è±¡ï¼ˆæ”¯æŒå¤šè¡Œå’ŒåµŒå¥—ï¼‰
            json_match = re.search(r'\{(?:[^{}]|{[^{}]*})*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                # æ¸…ç†JSONä¸­çš„æ³¨é‡Š
                json_str = re.sub(r'//.*?\n', '\n', json_str)  # åˆ é™¤å•è¡Œæ³¨é‡Š
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as parse_error:
                    logger.warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {parse_error}")
                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONé—®é¢˜
                    json_str = json_str.replace(',}', '}').replace(',]', ']')  # ç§»é™¤å¤šä½™é€—å·
                    try:
                        return json.loads(json_str)
                    except:
                        pass
            
            logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆJSONï¼Œå“åº”å¼€å¤´: {response_text[:200]}...")
            return self._get_default_market_report()
            
        except Exception as e:
            logger.warning(f"è§£æå¸‚åœºåˆ†æç»“æœå¤±è´¥: {e}")
            return self._get_default_market_report()
    
    def _get_default_extraction(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤çš„ä¿¡æ¯æå–ç»“æœ"""
        return {
            "responsibilities": ["å¾…æå–"],
            "hard_skills": {
                "required": [],
                "preferred": [],
                "bonus": []
            },
            "soft_skills": [],
            "experience_required": "æœªçŸ¥",
            "education_required": "æœªçŸ¥"
        }
    
    def _get_default_market_report(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤çš„å¸‚åœºåˆ†ææŠ¥å‘Š"""
        return {
            "market_overview": {
                "total_jobs_analyzed": len(getattr(self, '_current_job_list', [])),
                "analysis_date": datetime.now().strftime("%Y-%m-%d")
            },
            "skill_requirements": {
                "hard_skills": {
                    "core_required": [],
                    "important_preferred": [],
                    "special_scenarios": []
                },
                "soft_skills": {
                    "core_required": [],
                    "important_preferred": [],
                    "special_scenarios": []
                }
            },
            "core_responsibilities": ["åˆ†æå¤±è´¥"],
            "market_insights": {},
            "key_findings": ["å¸‚åœºåˆ†ææš‚æ—¶ä¸å¯ç”¨"]
        }
    
    def _get_fallback_analysis(self, error_msg: str) -> Dict[str, Any]:
        """è·å–é™çº§åˆ†æç»“æœ"""
        return {
            "overall_score": 0,
            "score": 0,
            "recommendation": "åˆ†æå¤±è´¥",
            "reason": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {error_msg}",
            "summary": "æ— æ³•å®Œæˆåˆ†æ",
            "dimension_scores": {},
            "match_highlights": [],
            "potential_concerns": ["åˆ†ææœåŠ¡å¼‚å¸¸"]
        }
    
    def get_market_analysis(self) -> Optional[Dict[str, Any]]:
        """è·å–å¸‚åœºåˆ†æç»“æœï¼ˆå…¼å®¹åŸJobAnalyzeræ¥å£ï¼‰"""
        if hasattr(self, 'market_report') and self.market_report:
            # è½¬æ¢æ–°æ ¼å¼åˆ°æ—§æ ¼å¼ä»¥ä¿æŒå‰ç«¯å…¼å®¹
            market_report = self.market_report
            
            # åˆå¹¶ç¡¬æŠ€èƒ½å’Œè½¯æŠ€èƒ½ä¸ºç»Ÿä¸€æ ¼å¼
            all_skills = []
            if 'skill_requirements' in market_report:
                skill_req = market_report['skill_requirements']
                
                # ç¡¬æŠ€èƒ½
                if 'hard_skills' in skill_req:
                    for category in ['core_required', 'important_preferred', 'special_scenarios']:
                        if category in skill_req['hard_skills']:
                            all_skills.extend(skill_req['hard_skills'][category])
                
                # è½¯æŠ€èƒ½  
                if 'soft_skills' in skill_req:
                    for category in ['core_required', 'important_preferred', 'special_scenarios']:
                        if category in skill_req['soft_skills']:
                            all_skills.extend(skill_req['soft_skills'][category])
            
            # è½¬æ¢ä¸ºæ—§ç‰ˆæœ¬å…¼å®¹æ ¼å¼
            return {
                'common_skills': all_skills[:20],  # å‰20ä¸ªæŠ€èƒ½
                'keyword_cloud': all_skills[:30],  # å…³é”®è¯äº‘
                'differentiation_analysis': {
                    'analysis': market_report.get('core_responsibilities', [])
                },
                'total_jobs_analyzed': market_report.get('market_overview', {}).get('total_jobs_analyzed', 0),
                'market_overview': market_report.get('market_overview', {}),  # æ·»åŠ å®Œæ•´çš„å¸‚åœºæ¦‚è§ˆ
                'skill_requirements': market_report.get('skill_requirements', {}),  # æ·»åŠ æŠ€èƒ½è¦æ±‚è¯¦æƒ…
                'market_insights': market_report.get('market_insights', {}),
                'key_findings': market_report.get('key_findings', [])
            }
        return None
    
    def filter_and_sort_jobs(self, analyzed_jobs: List[Dict[str, Any]], min_score: int = 6) -> List[Dict[str, Any]]:
        """è¿‡æ»¤å’Œæ’åºå²—ä½"""
        # è¿‡æ»¤ä½åˆ†å²—ä½
        filtered_jobs = [
            job for job in analyzed_jobs 
            if job.get('analysis', {}).get('score', 0) >= min_score
        ]
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_jobs = sorted(
            filtered_jobs, 
            key=lambda x: x.get('analysis', {}).get('score', 0), 
            reverse=True
        )
        
        print(f"ğŸ¯ ç­›é€‰ç»“æœ: {len(sorted_jobs)}/{len(analyzed_jobs)} ä¸ªå²—ä½è¾¾åˆ°æ ‡å‡†({min_score}åˆ†)")
        return sorted_jobs
    
    async def _stage1_quick_screening(self, jobs_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ1ï¼šå¿«é€Ÿç­›é€‰ç›¸å…³å²—ä½
        ä½¿ç”¨GLMåˆ¤æ–­å²—ä½æ˜¯å¦ä¸æ±‚èŒæ„å‘ç›¸å…³
        """
        relevant_jobs = []
        
        for i, job in enumerate(jobs_list, 1):
            if i % 10 == 0:
                print(f"   ç­›é€‰è¿›åº¦: {i}/{len(jobs_list)}")
            
            try:
                # è·å–ç­›é€‰æç¤ºè¯
                prompt = ExtractionPrompts.get_job_relevance_screening_prompt(job, self.user_intentions)
                
                # è°ƒç”¨GLMè¿›è¡Œå¿«é€Ÿåˆ¤æ–­ï¼Œè®¾ç½®temperature=0ä¿è¯ç¨³å®šè¾“å‡º
                response = self.extraction_service.call_api_simple(prompt, max_tokens=200, temperature=0.1)
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºGLMå“åº”
                if i == 1:
                    logger.info(f"GLMç­›é€‰å“åº”: {response[:200]}")
                
                # è§£æç»“æœ
                result = self._parse_screening_result(response)
                
                if result.get('relevant', False):
                    job['screening_reason'] = result.get('reason', '')
                    relevant_jobs.append(job)
                    if len(relevant_jobs) <= 3:
                        print(f"   âœ… ç›¸å…³å²—ä½: {job.get('title', '')} - {result.get('reason', '')}")
                
            except Exception as e:
                logger.error(f"ç­›é€‰å²—ä½{i}å¤±è´¥: {e}")
                # ç­›é€‰å¤±è´¥çš„é»˜è®¤ä¸åŒ…å«
        
        return relevant_jobs
    
    def _parse_screening_result(self, response_text: str) -> Dict[str, Any]:
        """è§£æç­›é€‰ç»“æœ"""
        try:
            import re
            
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*?\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œé»˜è®¤ä¸ºä¸ç›¸å…³
            return {"relevant": False, "reason": "è§£æå¤±è´¥"}
            
        except Exception as e:
            logger.error(f"è§£æç­›é€‰ç»“æœå¤±è´¥: {e}")
            return {"relevant": False, "reason": "è§£æå¼‚å¸¸"}
    
    def _merge_with_irrelevant_jobs(self, all_jobs: List[Dict[str, Any]], 
                                   analyzed_jobs: List[Dict[str, Any]], 
                                   relevant_jobs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶åˆ†æç»“æœï¼Œæ ‡è®°ä¸ç›¸å…³çš„å²—ä½
        """
        # åˆ›å»ºç›¸å…³å²—ä½çš„IDé›†åˆ
        relevant_ids = {job.get('link', job.get('title', '')) for job in relevant_jobs}
        analyzed_ids = {job.get('link', job.get('title', '')) for job in analyzed_jobs}
        
        result = []
        
        for job in all_jobs:
            job_id = job.get('link', job.get('title', ''))
            
            if job_id in analyzed_ids:
                # å·²åˆ†æçš„å²—ä½ï¼Œä»analyzed_jobsä¸­æ‰¾åˆ°å¯¹åº”ç»“æœ
                for analyzed_job in analyzed_jobs:
                    if analyzed_job.get('link', analyzed_job.get('title', '')) == job_id:
                        result.append(analyzed_job)
                        break
            else:
                # ä¸ç›¸å…³çš„å²—ä½ï¼Œæ ‡è®°ä¸º0åˆ†
                job['analysis'] = {
                    'score': 0,
                    'overall_score': 0,
                    'recommendation': 'D',
                    'reason': 'å²—ä½ä¸æ±‚èŒæ„å‘ä¸ç›¸å…³',
                    'summary': 'ç»å¿«é€Ÿç­›é€‰ï¼Œè¯¥å²—ä½ä¸æ‚¨çš„æ±‚èŒæ„å‘ä¸åŒ¹é…'
                }
                result.append(job)
        
        return result