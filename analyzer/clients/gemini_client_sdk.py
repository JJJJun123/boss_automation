#!/usr/bin/env python3
"""
Gemini APIå®¢æˆ·ç«¯ - ä½¿ç”¨å®˜æ–¹Google Generative AI SDK
çº¯APIè°ƒç”¨å™¨ï¼Œä¸åŒ…å«ä»»ä½•ä¸šåŠ¡é€»è¾‘å’Œæç¤ºè¯
"""

import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv
from ..base_client import BaseAIClient

# åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
config_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'config')
secrets_file = os.path.join(config_dir, 'secrets.env')
load_dotenv(secrets_file)

# å¯¼å…¥Google Generative AI SDK
try:
    import google.generativeai as genai
    GOOGLE_SDK_AVAILABLE = True
except ImportError:
    GOOGLE_SDK_AVAILABLE = False
    print("âš ï¸ Google Generative AI SDKæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")


class GeminiClientSDK(BaseAIClient):
    """Gemini APIå®¢æˆ·ç«¯ - ä½¿ç”¨å®˜æ–¹SDK"""
    
    def __init__(self, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨gemini-pro
        """
        super().__init__(model_name)
        
        if not GOOGLE_SDK_AVAILABLE:
            raise ImportError("Google Generative AI SDKæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")
        
        # è®¾ç½®é»˜è®¤æ¨¡å‹
        if not self.model_name:
            try:
                from config.config_manager import ConfigManager
                config_manager = ConfigManager()
                self.model_name = config_manager.get_app_config('ai.models.gemini.model_name', 'gemini-pro')
            except Exception:
                self.model_name = 'gemini-pro'
        
        # åˆå§‹åŒ–Google Generative AI
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            print("âš ï¸ è­¦å‘Š: æœªè®¾ç½®GEMINI_API_KEYï¼Œè¯·åœ¨config/secrets.envæ–‡ä»¶ä¸­é…ç½®")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(self.model_name)
        
        # ä»é…ç½®è¯»å–å‚æ•°
        try:
            from config.config_manager import ConfigManager
            config_manager = ConfigManager()
            gemini_config = config_manager.get_app_config('ai.models.gemini', {})
            self.temperature = gemini_config.get('temperature', 0.3)
            self.max_tokens = gemini_config.get('max_tokens', 1000)
        except Exception:
            self.temperature = 0.3
            self.max_tokens = 1000
        
        print(f"ğŸ¤– Geminiå®¢æˆ·ç«¯(SDKç‰ˆ)åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
        
        # éªŒè¯é…ç½®
        self._validate_configuration()
    
    def _validate_configuration(self) -> None:
        """éªŒè¯Geminié…ç½®"""
        if not os.getenv('GEMINI_API_KEY'):
            print("âš ï¸ è­¦å‘Š: æœªè®¾ç½®GEMINI_API_KEYï¼ŒAPIè°ƒç”¨å°†å¤±è´¥")
    
    def call_api(self, system_prompt: str, user_prompt: str, **kwargs) -> str:
        """
        è°ƒç”¨Gemini API - ç³»ç»Ÿæç¤ºè¯ + ç”¨æˆ·æç¤ºè¯æ¨¡å¼
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼‰
            
        Returns:
            AIå“åº”æ–‡æœ¬
        """
        # åˆå¹¶å‚æ•°
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        # Geminiå°†ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯åˆå¹¶
        combined_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        # åˆ›å»ºç”Ÿæˆé…ç½®
        generation_config = genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens
        )
        
        try:
            # ä½¿ç”¨å®˜æ–¹SDKè°ƒç”¨API
            response = self.model.generate_content(
                combined_prompt,
                generation_config=generation_config
            )
            
            # è¿”å›å“åº”å†…å®¹
            return response.text
            
        except Exception as e:
            error_msg = str(e)
            if "api_key" in error_msg.lower() or "authentication" in error_msg.lower():
                raise Exception("Gemini API Keyæœªé…ç½®æˆ–æ— æ•ˆ")
            elif "quota" in error_msg.lower() or "rate" in error_msg.lower():
                raise Exception("Gemini APIé…é¢ä¸è¶³æˆ–è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•")
            elif "model" in error_msg.lower():
                raise Exception(f"ä¸æ”¯æŒçš„æ¨¡å‹: {self.model_name}")
            else:
                raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {error_msg}")
    
    def call_api_simple(self, prompt: str, **kwargs) -> str:
        """
        ç®€å•APIè°ƒç”¨ - å•ä¸€æç¤ºè¯æ¨¡å¼
        
        Args:
            prompt: å®Œæ•´æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            AIå“åº”æ–‡æœ¬
        """
        # åˆå¹¶å‚æ•°
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        # åˆ›å»ºç”Ÿæˆé…ç½®
        generation_config = genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens
        )
        
        try:
            # ä½¿ç”¨å®˜æ–¹SDKè°ƒç”¨API
            response = self.model.generate_content(
                prompt,
                generation_config=generation_config
            )
            
            # è¿”å›å“åº”å†…å®¹
            return response.text
            
        except Exception as e:
            error_msg = str(e)
            if "api_key" in error_msg.lower() or "authentication" in error_msg.lower():
                raise Exception("Gemini API Keyæœªé…ç½®æˆ–æ— æ•ˆ")
            elif "quota" in error_msg.lower() or "rate" in error_msg.lower():
                raise Exception("Gemini APIé…é¢ä¸è¶³æˆ–è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•")
            else:
                raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {error_msg}")
    
    def call_api_stream(self, system_prompt: str, user_prompt: str, **kwargs):
        """
        æµå¼APIè°ƒç”¨ - æ”¯æŒå®æ—¶å“åº”
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            æµå¼å“åº”ç‰‡æ®µ
        """
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        # Geminiå°†ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯åˆå¹¶
        combined_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        # åˆ›å»ºç”Ÿæˆé…ç½®
        generation_config = genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens
        )
        
        try:
            # åˆ›å»ºæµå¼å“åº”
            response = self.model.generate_content(
                combined_prompt,
                generation_config=generation_config,
                stream=True
            )
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        except Exception as e:
            raise Exception(f"Geminiæµå¼APIè°ƒç”¨å¤±è´¥: {e}")