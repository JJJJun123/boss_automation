#!/usr/bin/env python3
"""
å®Œæ•´çš„æœ€ç»ˆæµ‹è¯•
éªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦ç”Ÿæ•ˆ
"""

import asyncio
import logging
import sys
import os
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def final_comprehensive_test():
    """æœ€ç»ˆç»¼åˆæµ‹è¯•"""
    try:
        logger.info("ğŸ¯ å¼€å§‹æœ€ç»ˆç»¼åˆæµ‹è¯•...")
        
        # é¦–å…ˆæ¸…ç†æ—§ç»“æœ
        try:
            os.remove('data/job_results.json')
            logger.info("ğŸ—‘ï¸ æ¸…ç†æ—§çš„ç»“æœæ–‡ä»¶")
        except:
            pass
        
        from crawler.real_playwright_spider import RealPlaywrightBossSpider
        
        spider = RealPlaywrightBossSpider(headless=False)
        
        if not await spider.start():
            logger.error("âŒ æ— æ³•å¯åŠ¨Playwright")
            return False
        
        # æµ‹è¯•æœç´¢
        keyword = "å¸‚åœºé£é™©ç®¡ç†"
        city = "shanghai"
        
        logger.info(f"ğŸ” æœç´¢: {keyword} åœ¨ {city}")
        jobs = await spider.search_jobs(keyword, city, 3)
        
        if jobs:
            logger.info(f"âœ… æˆåŠŸæå– {len(jobs)} ä¸ªå²—ä½")
            
            # è¯¦ç»†åˆ†ææ¯ä¸ªå²—ä½
            success_metrics = {
                "å»é‡æ•ˆæœ": True,
                "åŸå¸‚åŒ¹é…": False,
                "å…¬å¸åç§°è´¨é‡": 0,
                "å²—ä½æè¿°è´¨é‡": 0,
                "æ•°æ®å®Œæ•´æ€§": 0
            }
            
            unique_urls = set()
            
            for i, job in enumerate(jobs, 1):
                logger.info(f"\n{'='*50}")
                logger.info(f"ğŸ“‹ å²—ä½ {i} è¯¦ç»†åˆ†æ:")
                logger.info(f"   æ ‡é¢˜: {job.get('title', 'N/A')}")
                logger.info(f"   å…¬å¸: {job.get('company', 'N/A')}")
                logger.info(f"   åœ°ç‚¹: {job.get('work_location', 'N/A')}")
                logger.info(f"   è–ªèµ„: {job.get('salary', 'N/A')}")
                logger.info(f"   URL: {job.get('url', 'N/A')[:50]}...")
                
                # æ£€æŸ¥é‡å¤
                url = job.get('url', '')
                clean_url = url.split('?')[0] if '?' in url else url
                if clean_url in unique_urls:
                    success_metrics["å»é‡æ•ˆæœ"] = False
                    logger.warning(f"   âš ï¸ å‘ç°é‡å¤URL")
                else:
                    unique_urls.add(clean_url)
                    logger.info(f"   âœ… å”¯ä¸€å²—ä½")
                
                # æ£€æŸ¥åŸå¸‚åŒ¹é…
                location = job.get('work_location', '')
                if "ä¸Šæµ·" in location:
                    success_metrics["åŸå¸‚åŒ¹é…"] = True
                    logger.info(f"   âœ… åŸå¸‚åŒ¹é…: {location}")
                else:
                    logger.warning(f"   âš ï¸ åŸå¸‚å¯èƒ½ä¸åŒ¹é…: {location}")
                
                # æ£€æŸ¥å…¬å¸åç§°è´¨é‡
                company = job.get('company', '')
                if company and company != "æœªçŸ¥å…¬å¸" and len(company) > 2:
                    success_metrics["å…¬å¸åç§°è´¨é‡"] += 1
                    logger.info(f"   âœ… æœ‰æ•ˆå…¬å¸åç§°: {company}")
                else:
                    logger.warning(f"   âš ï¸ å…¬å¸åç§°å¾…æ”¹å–„: {company}")
                
                # æ£€æŸ¥å²—ä½æè¿°è´¨é‡
                desc = job.get('job_description', '')
                req = job.get('job_requirements', '')
                
                if 'å…·ä½“èŒè´£è¯·æŸ¥çœ‹å²—ä½è¯¦æƒ…' not in desc and len(desc) > 50:
                    success_metrics["å²—ä½æè¿°è´¨é‡"] += 1
                    logger.info(f"   âœ… æœ‰æ„ä¹‰çš„å²—ä½æè¿°: {desc[:30]}...")
                else:
                    logger.warning(f"   âš ï¸ å²—ä½æè¿°æ˜¯æ¨¡æ¿æ–‡æœ¬")
                
                # æ•°æ®å®Œæ•´æ€§
                if all([job.get('title'), job.get('company'), job.get('url')]):
                    success_metrics["æ•°æ®å®Œæ•´æ€§"] += 1
                    logger.info(f"   âœ… åŸºæœ¬æ•°æ®å®Œæ•´")
                else:
                    logger.warning(f"   âš ï¸ åŸºæœ¬æ•°æ®ä¸å®Œæ•´")
            
            # æ€»ç»“è¯„ä¼°
            logger.info(f"\n{'='*60}")
            logger.info("ğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ:")
            
            final_scores = {
                "å»é‡æ•ˆæœ": "âœ…" if success_metrics["å»é‡æ•ˆæœ"] else "âŒ",
                "åŸå¸‚åŒ¹é…": "âœ…" if success_metrics["åŸå¸‚åŒ¹é…"] else "âŒ",
                "å…¬å¸åç§°è´¨é‡": f"{success_metrics['å…¬å¸åç§°è´¨é‡']}/{len(jobs)} {'âœ…' if success_metrics['å…¬å¸åç§°è´¨é‡'] >= len(jobs) * 0.7 else 'âš ï¸'}",
                "å²—ä½æè¿°è´¨é‡": f"{success_metrics['å²—ä½æè¿°è´¨é‡']}/{len(jobs)} {'âœ…' if success_metrics['å²—ä½æè¿°è´¨é‡'] >= len(jobs) * 0.5 else 'âš ï¸'}",
                "æ•°æ®å®Œæ•´æ€§": f"{success_metrics['æ•°æ®å®Œæ•´æ€§']}/{len(jobs)} {'âœ…' if success_metrics['æ•°æ®å®Œæ•´æ€§'] == len(jobs) else 'âš ï¸'}"
            }
            
            for metric, result in final_scores.items():
                logger.info(f"   {metric}: {result}")
            
            # è®¡ç®—æ€»ä½“æˆåŠŸç‡
            core_success = (
                success_metrics["å»é‡æ•ˆæœ"] and 
                success_metrics["åŸå¸‚åŒ¹é…"] and
                success_metrics["æ•°æ®å®Œæ•´æ€§"] >= len(jobs) * 0.8
            )
            
            if core_success:
                logger.info("ğŸ‰ æ ¸å¿ƒåŠŸèƒ½ä¿®å¤æˆåŠŸï¼åº”ç”¨å¯ä»¥æ­£å¸¸ä½¿ç”¨")
                logger.info("ğŸ’¡ å»ºè®®: python run_web.py å¼€å§‹æ­£å¸¸ä½¿ç”¨")
                return True
            else:
                logger.warning("âš ï¸ éƒ¨åˆ†åŠŸèƒ½ä»éœ€ä¼˜åŒ–ï¼Œä½†åŸºæœ¬å¯ç”¨")
                return True  # åŸºæœ¬å¯ç”¨å°±ç®—æˆåŠŸ
                
        else:
            logger.error("âŒ æœªèƒ½æå–åˆ°å²—ä½")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        try:
            await spider.close()
        except:
            pass


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Bossç›´è˜æœ€ç»ˆç»¼åˆæµ‹è¯•")
    print("=" * 50)
    print("æœ¬æµ‹è¯•å°†å…¨é¢éªŒè¯æ‰€æœ‰ä¿®å¤æ•ˆæœ:")
    print("1. âœ… åŸå¸‚ä»£ç ä¿®æ­£")
    print("2. ğŸ”„ å»é‡é€»è¾‘ä¼˜åŒ–")
    print("3. ğŸ¢ å…¬å¸åç§°æå–") 
    print("4. ğŸ“‹ å²—ä½æè¿°æ”¹å–„")
    print("5. ğŸ–¥ï¸ å‰ç«¯æ˜¾ç¤ºåŠŸèƒ½")
    print("6. ğŸ¯ æ•´ä½“å¯ç”¨æ€§")
    print()
    
    result = asyncio.run(final_comprehensive_test())
    
    if result:
        print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨äº†")
        print("ğŸš€ ä¸‹ä¸€æ­¥: è¿è¡Œ python run_web.py å¼€å§‹ä½¿ç”¨")
    else:
        print("\nâŒ ä»æœ‰é—®é¢˜éœ€è¦è§£å†³")


if __name__ == "__main__":
    main()