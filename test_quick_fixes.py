#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•å’ŒéªŒè¯å½“å‰ä¿®å¤æ•ˆæœ
æ£€æŸ¥å»é‡å’Œå­—æ®µæå–é—®é¢˜
"""

import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def quick_test():
    """å¿«é€Ÿæµ‹è¯•ä¿®å¤æ•ˆæœ"""
    try:
        from crawler.real_playwright_spider import RealPlaywrightBossSpider
        
        logger.info("ğŸš€ å¿«é€Ÿæµ‹è¯•ä¿®å¤æ•ˆæœ...")
        
        spider = RealPlaywrightBossSpider(headless=False)
        
        if not await spider.start():
            logger.error("âŒ æ— æ³•å¯åŠ¨Playwright")
            return
        
        # æµ‹è¯•æœç´¢
        keyword = "å¸‚åœºé£é™©ç®¡ç†"
        city = "shanghai"
        
        logger.info(f"ğŸ” æœç´¢: {keyword} åœ¨ {city}")
        jobs = await spider.search_jobs(keyword, city, 3)  # åªæµ‹è¯•3ä¸ªå²—ä½
        
        if jobs:
            logger.info(f"âœ… æˆåŠŸæå– {len(jobs)} ä¸ªå²—ä½")
            
            # æ£€æŸ¥é‡å¤é—®é¢˜
            unique_urls = set()
            duplicates = []
            
            for i, job in enumerate(jobs, 1):
                url = job.get('url', '')
                clean_url = url.split('?')[0] if '?' in url and url else url
                
                logger.info(f"\nğŸ“‹ å²—ä½ {i}:")
                logger.info(f"   æ ‡é¢˜: {job.get('title', 'N/A')}")
                logger.info(f"   å…¬å¸: {job.get('company', 'N/A')}")
                logger.info(f"   åœ°ç‚¹: {job.get('work_location', 'N/A')}")
                logger.info(f"   URL: {clean_url}")
                
                # æ£€æŸ¥é‡å¤
                if clean_url in unique_urls:
                    duplicates.append(i)
                    logger.warning(f"   âš ï¸ é‡å¤URLå‘ç°ï¼")
                else:
                    unique_urls.add(clean_url)
                    logger.info(f"   âœ… å”¯ä¸€å²—ä½")
                
                # æ£€æŸ¥å²—ä½æè¿°é—®é¢˜
                desc = job.get('job_description', '')
                req = job.get('job_requirements', '')
                
                if 'å…·ä½“èŒè´£è¯·æŸ¥çœ‹å²—ä½è¯¦æƒ…' in desc:
                    logger.warning(f"   âš ï¸ å²—ä½æè¿°æ˜¯æ¨¡æ¿æ–‡æœ¬")
                else:
                    logger.info(f"   âœ… å²—ä½æè¿°: {desc[:50]}...")
                
                if 'è¦æ±‚1-3å¹´å·¥ä½œç»éªŒ' in req or 'è¦æ±‚å·¥ä½œç»éªŒ' in req:
                    logger.warning(f"   âš ï¸ ä»»èŒè¦æ±‚æ˜¯æ¨¡æ¿æ–‡æœ¬")
                else:
                    logger.info(f"   âœ… ä»»èŒè¦æ±‚: {req[:50]}...")
            
            # æ€»ç»“
            logger.info(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
            logger.info(f"   æ€»å²—ä½æ•°: {len(jobs)}")
            logger.info(f"   å”¯ä¸€å²—ä½æ•°: {len(unique_urls)}")
            logger.info(f"   é‡å¤å²—ä½æ•°: {len(duplicates)}")
            
            success_metrics = {
                "å»é‡æ•ˆæœ": len(duplicates) == 0,
                "åŸå¸‚åŒ¹é…": any("ä¸Šæµ·" in job.get('work_location', '') for job in jobs),
                "å­—æ®µå®Œæ•´": all(job.get('title') and job.get('company') for job in jobs)
            }
            
            for metric, result in success_metrics.items():
                status = "âœ…" if result else "âŒ"
                logger.info(f"   {metric}: {status}")
            
            overall_success = sum(success_metrics.values()) >= 2
            
            if overall_success:
                logger.info("ğŸ‰ æ€»ä½“ä¿®å¤æ•ˆæœè‰¯å¥½ï¼")
            else:
                logger.warning("âš ï¸ ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
                
            return overall_success
            
        else:
            logger.warning("âš ï¸ æœªæå–åˆ°å²—ä½")
            return False
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        try:
            await spider.close()
        except:
            pass


def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ Bossç›´è˜å¿«é€Ÿä¿®å¤æµ‹è¯•")
    print("=" * 40)
    
    result = asyncio.run(quick_test())
    
    if result:
        print("\nâœ… å¿«é€Ÿæµ‹è¯•é€šè¿‡")
        print("ğŸ’¡ å¯ä»¥è¿è¡Œå®Œæ•´åº”ç”¨: python run_web.py")
    else:
        print("\nâŒ å¿«é€Ÿæµ‹è¯•æœªé€šè¿‡")
        print("ğŸ’¡ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œä¿®å¤")


if __name__ == "__main__":
    main()