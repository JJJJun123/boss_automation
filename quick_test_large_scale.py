#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•å¤§è§„æ¨¡æŠ“å–ä¼˜åŒ–åŠŸèƒ½
"""

import os
import sys
import asyncio
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ç®€å•çš„æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_job_requirement_summarizer():
    """æµ‹è¯•AIå²—ä½è¦æ±‚æ€»ç»“å™¨"""
    logger.info("ğŸ§  æµ‹è¯•AIå²—ä½è¦æ±‚æ€»ç»“å™¨...")
    
    try:
        from analyzer.job_requirement_summarizer import JobRequirementSummarizer
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_jobs = [
            {
                "title": "AIç®—æ³•å·¥ç¨‹å¸ˆ",
                "company": "æµ‹è¯•å…¬å¸A",
                "job_description": "è´Ÿè´£æœºå™¨å­¦ä¹ ç®—æ³•å¼€å‘å’Œä¼˜åŒ–ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¨¡å‹è®¾è®¡ã€æ•°æ®é¢„å¤„ç†ç­‰å·¥ä½œã€‚",
                "job_requirements": "è¦æ±‚3å¹´ä»¥ä¸ŠAIç®—æ³•ç»éªŒï¼Œç†Ÿç»ƒæŒæ¡Pythonã€TensorFlowç­‰å·¥å…·ï¼Œæœ¬ç§‘ä»¥ä¸Šå­¦å†ã€‚",
                "salary": "20K-30K",
                "work_location": "ä¸Šæµ·"
            },
            {
                "title": "æ•°æ®åˆ†æå¸ˆ",
                "company": "æµ‹è¯•å…¬å¸B", 
                "job_description": "è´Ÿè´£ä¸šåŠ¡æ•°æ®åˆ†æï¼Œåˆ¶ä½œæ•°æ®æŠ¥è¡¨ï¼Œæ”¯æŒä¸šåŠ¡å†³ç­–ã€‚",
                "job_requirements": "ç»Ÿè®¡å­¦æˆ–ç›¸å…³ä¸“ä¸šï¼Œç†Ÿæ‚‰SQLã€Pythonï¼Œæœ‰2å¹´ä»¥ä¸Šæ•°æ®åˆ†æç»éªŒã€‚",
                "salary": "15K-25K",
                "work_location": "åŒ—äº¬"
            }
        ]
        
        # æµ‹è¯•æ€»ç»“å™¨
        summarizer = JobRequirementSummarizer("deepseek")
        
        # æµ‹è¯•å•ä¸ªå²—ä½æ€»ç»“
        logger.info("ğŸ” æµ‹è¯•å•ä¸ªå²—ä½æ€»ç»“...")
        single_summary = await summarizer.summarize_single_job(test_jobs[0])
        logger.info(f"âœ… å•ä¸ªæ€»ç»“å®Œæˆï¼Œç½®ä¿¡åº¦: {single_summary.summary_confidence:.2f}")
        logger.info(f"   æ ¸å¿ƒèŒè´£: {single_summary.core_responsibilities[:2]}")
        logger.info(f"   å…³é”®è¦æ±‚: {single_summary.key_requirements[:2]}")
        
        # æµ‹è¯•æ‰¹é‡æ€»ç»“
        logger.info("ğŸ”„ æµ‹è¯•æ‰¹é‡å²—ä½æ€»ç»“...")
        batch_summaries = await summarizer.summarize_batch_jobs(test_jobs)
        logger.info(f"âœ… æ‰¹é‡æ€»ç»“å®Œæˆ: {len(batch_summaries)} ä¸ªå²—ä½")
        
        # è·å–æˆæœ¬æŠ¥å‘Š
        cost_report = summarizer.get_cost_savings_report()
        logger.info("ğŸ’° æˆæœ¬ä¼˜åŒ–æŠ¥å‘Š:")
        logger.info(f"   ç¼“å­˜å‘½ä¸­ç‡: {cost_report.get('cache_statistics', {}).get('cache_hit_rate', '0%')}")
        logger.info(f"   èŠ‚çœæˆæœ¬: {cost_report.get('cost_analysis', {}).get('total_savings', 'Â¥0.00')}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_configuration_updates():
    """æµ‹è¯•é…ç½®æ›´æ–°"""
    logger.info("âš™ï¸ æµ‹è¯•é…ç½®æ›´æ–°...")
    
    try:
        from config.config_manager import ConfigManager
        
        config_manager = ConfigManager()
        search_config = config_manager.get_search_config()
        
        logger.info(f"ğŸ“Š å½“å‰æœç´¢é…ç½®:")
        logger.info(f"   æœ€å¤§å²—ä½æ•°: {search_config.get('max_jobs', 20)}")
        logger.info(f"   æœ€å¤§åˆ†ææ•°: {search_config.get('max_analyze_jobs', 10)}")
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒå¤§è§„æ¨¡æŠ“å–
        max_jobs = search_config.get('max_jobs', 20)
        if max_jobs >= 50:
            logger.info("âœ… é…ç½®æ”¯æŒå¤§è§„æ¨¡æŠ“å–")
        else:
            logger.warning(f"âš ï¸ å½“å‰é…ç½®æœ€å¤§å²—ä½æ•°ä»…ä¸º {max_jobs}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_large_scale_crawler_import():
    """æµ‹è¯•å¤§è§„æ¨¡çˆ¬è™«å¯¼å…¥"""
    logger.info("ğŸ­ æµ‹è¯•å¤§è§„æ¨¡çˆ¬è™«æ¨¡å—å¯¼å…¥...")
    
    try:
        from crawler.large_scale_crawler import LargeScaleCrawler, LargeScaleProgressTracker
        logger.info("âœ… å¤§è§„æ¨¡çˆ¬è™«æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        from crawler.real_playwright_spider import RealPlaywrightBossSpider
        logger.info("âœ… çœŸå®Playwrightçˆ¬è™«æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸ¯ Bossç›´è˜å¤§è§„æ¨¡æŠ“å–ä¼˜åŒ–å¿«é€Ÿæµ‹è¯•")
    logger.info("=" * 50)
    
    tests = [
        ("é…ç½®æ›´æ–°", test_configuration_updates),
        ("æ¨¡å—å¯¼å…¥", test_large_scale_crawler_import),
        ("AIå²—ä½è¦æ±‚æ€»ç»“", test_job_requirement_summarizer),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ§ª æ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results[test_name] = result
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯• {test_name} å‡ºé”™: {e}")
            results[test_name] = False
    
    # æ€»ç»“
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    success_count = sum(1 for result in results.values() if result)
    total_count = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"   {test_name}: {status}")
    
    logger.info(f"\nğŸ¯ æ€»ä½“ç»“æœ: {success_count}/{total_count} æµ‹è¯•é€šè¿‡")
    
    if success_count == total_count:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤§è§„æ¨¡æŠ“å–ä¼˜åŒ–åŠŸèƒ½å°±ç»ª")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()