#!/usr/bin/env python3
"""
ç»Ÿä¸€çˆ¬è™«å¼•æ“æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–°çš„ç»Ÿä¸€çˆ¬è™«æ¶æ„æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import logging
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from crawler.unified_spider import UnifiedSpider
from crawler.unified_crawler_interface import unified_search_jobs
from config.config_manager import ConfigManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_direct_spider():
    """ç›´æ¥æµ‹è¯•ç»Ÿä¸€çˆ¬è™«å¼•æ“"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•1: ç›´æ¥ä½¿ç”¨ UnifiedSpider")
    print("="*60)
    
    spider = UnifiedSpider(headless=False)  # ä½¿ç”¨æœ‰å¤´æ¨¡å¼ä¾¿äºè°ƒè¯•
    
    try:
        # å¯åŠ¨çˆ¬è™«
        logger.info("ğŸš€ å¯åŠ¨ç»Ÿä¸€çˆ¬è™«å¼•æ“...")
        started = await spider.start()
        if not started:
            print("âŒ çˆ¬è™«å¯åŠ¨å¤±è´¥")
            return False
        
        print("âœ… çˆ¬è™«å¼•æ“å¯åŠ¨æˆåŠŸ")
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        test_params = {
            "keyword": "Pythonå¼€å‘",
            "city": "shanghai",
            "max_jobs": 5,
            "use_cache": False  # å¼ºåˆ¶ä¸ä½¿ç”¨ç¼“å­˜ï¼Œç¡®ä¿çœŸå®çˆ¬å–
        }
        
        print(f"\nğŸ” æœç´¢å‚æ•°:")
        for key, value in test_params.items():
            print(f"   {key}: {value}")
        
        # æ‰§è¡Œæœç´¢
        print("\nâ³ å¼€å§‹æœç´¢...")
        start_time = datetime.now()
        
        jobs = await spider.search_jobs(
            keyword=test_params["keyword"],
            city=test_params["city"],
            max_jobs=test_params["max_jobs"],
            use_cache=test_params["use_cache"],
            callback=lambda msg: print(f"   ğŸ“¢ {msg}")
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… æœç´¢å®Œæˆ! è€—æ—¶: {duration:.2f}ç§’")
        print(f"ğŸ“Š æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½\n")
        
        # æ˜¾ç¤ºå‰3ä¸ªå²—ä½çš„è¯¦ç»†ä¿¡æ¯
        for i, job in enumerate(jobs[:3], 1):
            print(f"ã€å²—ä½ {i}ã€‘")
            print(f"  èŒä½: {job.get('title', 'N/A')}")
            print(f"  å…¬å¸: {job.get('company', 'N/A')}")
            print(f"  è–ªèµ„: {job.get('salary', 'N/A')}")
            print(f"  åœ°åŒº: {job.get('location', 'N/A')}")
            print(f"  ç»éªŒ: {job.get('experience', 'N/A')}")
            print(f"  å­¦å†: {job.get('education', 'N/A')}")
            print(f"  å¼•æ“: {job.get('engine_source', 'N/A')}")
            print()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = spider.get_stats()
        print("ğŸ“ˆ çˆ¬è™«ç»Ÿè®¡:")
        print(f"  æ€»æœç´¢æ¬¡æ•°: {stats['total_searches']}")
        print(f"  æˆåŠŸæ¬¡æ•°: {stats['successful_searches']}")
        print(f"  ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {stats['cache_hits']}")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.2f}ç§’")
        
        return len(jobs) > 0
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False
        
    finally:
        # å…³é—­çˆ¬è™«
        await spider.close()
        print("\nğŸ”’ çˆ¬è™«å¼•æ“å·²å…³é—­")


async def test_unified_interface():
    """æµ‹è¯•ç»Ÿä¸€æ¥å£"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•2: ä½¿ç”¨ unified_search_jobs æ¥å£")
    print("="*60)
    
    try:
        # æµ‹è¯•å‚æ•°
        test_params = {
            "keyword": "æ•°æ®åˆ†æ",
            "city": "beijing",
            "max_jobs": 3,
            "use_cache": True  # å…è®¸ä½¿ç”¨ç¼“å­˜
        }
        
        print(f"\nğŸ” æœç´¢å‚æ•°:")
        for key, value in test_params.items():
            print(f"   {key}: {value}")
        
        # æ‰§è¡Œæœç´¢
        print("\nâ³ å¼€å§‹æœç´¢...")
        start_time = datetime.now()
        
        jobs = await unified_search_jobs(
            keyword=test_params["keyword"],
            city=test_params["city"],
            max_jobs=test_params["max_jobs"],
            use_cache=test_params["use_cache"]
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nâœ… æœç´¢å®Œæˆ! è€—æ—¶: {duration:.2f}ç§’")
        print(f"ğŸ“Š æ‰¾åˆ° {len(jobs)} ä¸ªå²—ä½")
        
        if jobs:
            print("\nâœ… ç»Ÿä¸€æ¥å£æµ‹è¯•æˆåŠŸ!")
            # æ£€æŸ¥æ˜¯å¦å‘½ä¸­ç¼“å­˜
            if any("ç¼“å­˜" in job.get("engine_source", "") for job in jobs):
                print("ğŸ“¦ å‘½ä¸­ç¼“å­˜")
        else:
            print("\nâŒ æœªæ‰¾åˆ°å²—ä½æ•°æ®")
        
        return len(jobs) > 0
        
    except Exception as e:
        logger.error(f"æ¥å£æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


async def test_cache_functionality():
    """æµ‹è¯•ç¼“å­˜åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•3: ç¼“å­˜åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    try:
        # ç¬¬ä¸€æ¬¡æœç´¢ï¼ˆæ— ç¼“å­˜ï¼‰
        print("\nğŸ“ ç¬¬ä¸€æ¬¡æœç´¢ï¼ˆåº”è¯¥æ²¡æœ‰ç¼“å­˜ï¼‰:")
        start_time1 = datetime.now()
        jobs1 = await unified_search_jobs(
            keyword="å‰ç«¯å¼€å‘",
            city="hangzhou",
            max_jobs=2,
            use_cache=True
        )
        duration1 = (datetime.now() - start_time1).total_seconds()
        print(f"  è€—æ—¶: {duration1:.2f}ç§’")
        print(f"  ç»“æœ: {len(jobs1)} ä¸ªå²—ä½")
        
        # ç¬¬äºŒæ¬¡æœç´¢ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
        print("\nğŸ“ ç¬¬äºŒæ¬¡æœç´¢ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰:")
        start_time2 = datetime.now()
        jobs2 = await unified_search_jobs(
            keyword="å‰ç«¯å¼€å‘",
            city="hangzhou",
            max_jobs=2,
            use_cache=True
        )
        duration2 = (datetime.now() - start_time2).total_seconds()
        print(f"  è€—æ—¶: {duration2:.2f}ç§’")
        print(f"  ç»“æœ: {len(jobs2)} ä¸ªå²—ä½")
        
        # éªŒè¯ç¼“å­˜æ•ˆæœ
        if duration2 < duration1 * 0.5:  # ç¼“å­˜åº”è¯¥å¿«å¾ˆå¤š
            print("\nâœ… ç¼“å­˜åŠŸèƒ½æ­£å¸¸! ç¬¬äºŒæ¬¡æœç´¢æ˜æ˜¾æ›´å¿«")
        else:
            print("\nâš ï¸ ç¼“å­˜å¯èƒ½æœªç”Ÿæ•ˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"ç¼“å­˜æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Bossç›´è˜ç»Ÿä¸€çˆ¬è™«å¼•æ“æµ‹è¯•")
    print("="*60)
    
    # åˆå§‹åŒ–é…ç½®
    config_manager = ConfigManager()
    print("âœ… é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # è¿è¡Œæµ‹è¯•
    test_results = []
    
    # æµ‹è¯•1: ç›´æ¥ä½¿ç”¨çˆ¬è™«å¼•æ“
    result1 = await test_direct_spider()
    test_results.append(("ç›´æ¥çˆ¬è™«å¼•æ“", result1))
    
    # æµ‹è¯•2: ä½¿ç”¨ç»Ÿä¸€æ¥å£
    result2 = await test_unified_interface()
    test_results.append(("ç»Ÿä¸€æ¥å£", result2))
    
    # æµ‹è¯•3: ç¼“å­˜åŠŸèƒ½
    result3 = await test_cache_functionality()
    test_results.append(("ç¼“å­˜åŠŸèƒ½", result3))
    
    # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    all_passed = True
    for test_name, passed in test_results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    return all_passed


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())
    sys.exit(0 if success else 1)